{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.7.1\n",
      "Torchvision Version:  0.8.2\n"
     ]
    }
   ],
   "source": [
    "import datetime                  # test + Uncertainty\n",
    "import pandas as pd              # test + Uncertainty\n",
    "import numpy as np               # test + Uncertainty\n",
    "import pickle5 as pickle                    # Uncertainty\n",
    "from tqdm import tqdm\n",
    "\n",
    "#import test_model as tm          # test\n",
    "import test_uncertainty_Softmax_v2 as tuc   # Uncertainty\n",
    "from humanfriendly import format_timespan\n",
    "\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import performance\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from scipy.special import entr\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_pretrained_models as ppm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "from configparser import ConfigParser\n",
    "import custom_dataset_TTA as cds\n",
    "import data_ops as do\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import datasets, models, transforms\n",
    "from scipy.special import softmax\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-27 11:12:54.369914\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResizeLargerSide(object):\n",
    "    def __init__(self, output_size):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "    def __call__(self, img):\n",
    "        w, h = img.size\n",
    "        if h < w:\n",
    "            new_w = self.output_size\n",
    "            new_h = int(h*(self.output_size/w))\n",
    "        elif w < h:\n",
    "            new_h = self.output_size\n",
    "            new_w = int(w*(self.output_size/h))\n",
    "        else:  # w == h\n",
    "            new_w = self.output_size\n",
    "            new_h = self.output_size\n",
    "        resized_img = img.resize((new_w, new_h))\n",
    "        return resized_img\n",
    "\n",
    "class RandomPad(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "    def __call__(self, image):\n",
    "        w, h = image.size\n",
    "        new_h, new_w = self.output_size\n",
    "        color = (255, 255, 255)\n",
    "        pad_top, pad_bottom, pad_l, pad_r = 0, 0, 0, 0\n",
    "        if h < new_h:  # need to pad height\n",
    "            pad_top = np.random.randint(0, new_h - h)\n",
    "        if w < new_w:  # need to pad width\n",
    "            pad_l = np.random.randint(0, new_w - w)\n",
    "        padded_img = Image.new(image.mode, (new_w, new_h), color)\n",
    "        padded_img.paste(image, (pad_l, pad_top))\n",
    "        return padded_img\n",
    "    \n",
    "# MEAN = [0.6802, 0.6802, 0.6802]\n",
    "# STD = [0.2875, 0.2875, 0.2875]\n",
    "MEAN = [0, 0, 0]\n",
    "STD = [1, 1, 1]\n",
    "#MEAN = [0.485, 0.456, 0.406]\n",
    "#STD = [0.229, 0.224, 0.225]\n",
    "SIZE = 224\n",
    "RESIZE_RATIO = 0.9\n",
    "input_size=224\n",
    "\n",
    "IMAGE_SIZE=224\n",
    "scale = 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _random_colour_space(x):\n",
    "    output = x.convert(\"HSV\") # HSV, YUV, and LAB\n",
    "    return output\n",
    "\n",
    "class GaussianNoise():\n",
    "    \"\"\"Adds gaussian noise to a tensor.\n",
    "\n",
    "        >>> transforms.Compose([\n",
    "        >>>     transforms.ToTensor(),\n",
    "        >>>     Noise(0.1, 0.05)),\n",
    "        >>> ])\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, mean, stddev):\n",
    "        self.mean = mean\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        noise = torch.zeros_like(tensor).normal_(self.mean, self.stddev)\n",
    "        return tensor.add_(noise)\n",
    "\n",
    "    def __repr__(self):\n",
    "        repr = f\"{self.__class__.__name__  }(mean={self.mean}, stddev={self.stddev})\"\n",
    "        return repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms_augmentation = {\n",
    "                'train': transforms.Compose([\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    #transforms.RandomRotation(80, expand=True, center=None, fill=255),\n",
    "                    ResizeLargerSide(int(RESIZE_RATIO*SIZE)),\n",
    "                    #RandomPad(SIZE),\n",
    "                    transforms.CenterCrop(SIZE),\n",
    "                    #transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(MEAN, STD)\n",
    "                ]), \n",
    "    \n",
    "                'val2': transforms.Compose([\n",
    "                      transforms.Resize(input_size),\n",
    "#                     transforms.Scale(SIZE),\n",
    "                      #transforms.TenCrop(input_size),\n",
    "#                       transforms.RandomRotation(180, expand=True, center=None, fill=255),\n",
    "                      ResizeLargerSide(int(RESIZE_RATIO*SIZE)),\n",
    "                      transforms.CenterCrop(SIZE),\n",
    "                      transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
    "#                       transforms.Lambda(lambda normal: torch.stack([transforms.Normalize(MEAN, STD)(normalize) for normalize in normal]))\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize(MEAN, STD)\n",
    "                 ]),\n",
    "    \n",
    "                'val': transforms.Compose([                    \n",
    "                    ResizeLargerSide(int(RESIZE_RATIO*SIZE)),\n",
    "                    transforms.Pad(SIZE//2, 255),\n",
    "                    transforms.CenterCrop(SIZE),\n",
    "                    #transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
    "                    transforms.Normalize(MEAN, STD)\n",
    "                ]),\n",
    "                'val4': transforms.Compose([\n",
    "                    # order is also impostant, when I added this to the end, it failed to work\n",
    "                    #transforms.RandomResizedCrop(200, scale=(0.08, 1.0), ratio=(0.75, 1.33)), # bad=12.5\n",
    "                    transforms.ColorJitter(brightness=0.6, contrast=0.6), # bad=10%\n",
    "                    #transforms.RandomPerspective(distortion_scale=0.5, p=0.5, fill=0), # bad=95% to 83%\n",
    "                    #transforms.RandomRotation(18, expand=True, center=None, fill=255),#no impact\n",
    "                    #transforms.RandomRotation(18), # bad=53% if applied before standard transformations\n",
    "                    #transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False),\n",
    "                    #transforms.RandomErasing(p=0.5, scale=(0.02, 0.15), ratio=(0.1, 0.8), value=1, inplace=False),  # 10%\n",
    "                    #transforms.functional.autocontrast(),\n",
    "#                     transforms.Lambda(lambda x: _random_colour_space(x)),\n",
    "                    #RGB, HSV, YUV, and LAB > this transform is applied to Image object so, it must be used\n",
    "                    # before ToTensor()\n",
    "                    #transforms.RandomApply([transforms.Lambda(lambda x: _random_colour_space(x))]), # no impact\n",
    "                    #transforms.RandomHorizontalFlip(), # doesn't make any effect\n",
    "                    ResizeLargerSide(int(RESIZE_RATIO*SIZE)),\n",
    "                    transforms.Pad(SIZE//2, 255),\n",
    "#                     transforms.RandomCrop(0.5, padding=None, pad_if_needed=False, fill=0, padding_mode='constant'),\n",
    "                    transforms.CenterCrop(SIZE),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(MEAN, STD),   \n",
    "                    #transforms.RandomRotation(18), # if used after standard transformations, just slightly drops the accuracy > 93.75\n",
    "                    #transforms.GaussianBlur(11, sigma=(0.1, 2.0)) # no impact\n",
    "                    #transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False), # no impact\n",
    "                    #transforms.RandomErasing(p=0.5, scale=(0.02, 0.15), ratio=(0.1, 0.8), value=1, inplace=False),  # no impact\n",
    "                    #transforms.RandomPerspective(distortion_scale=0.2, p=0.5, fill=0), # bad=95% to 93.75%\n",
    "                    #transforms.RandomGrayscale(p=0.01), # ok=no impact=95.3125%\n",
    "                    #GaussianNoise(mean=0.1,sttdev=0.05)\n",
    "                    #GaussianNoise(0.1,0.05) #bad = 4.7%\n",
    "#                     A.ColorJitter(brightness=0.6, contrast=0.6, saturation=0.6, hue=0.6, p=0.4),\n",
    "                ]),\n",
    "                'albumentations': A.Compose(\n",
    "                        [\n",
    "                            A.LongestMaxSize(max_size=int(IMAGE_SIZE * scale)),\n",
    "                            A.PadIfNeeded(\n",
    "                                min_height=int(IMAGE_SIZE * scale),\n",
    "                                min_width=int(IMAGE_SIZE * scale),\n",
    "                                border_mode=cv2.BORDER_CONSTANT,\n",
    "                            ),\n",
    "#                             A.RandomCrop(width=IMAGE_SIZE, height=IMAGE_SIZE),\n",
    "#                             A.ColorJitter(brightness=0.6, contrast=0.6, saturation=0.6, hue=0.6, p=0.4),\n",
    "#                             A.OneOf(\n",
    "#                                 [\n",
    "#                                     A.ShiftScaleRotate(\n",
    "#                                         rotate_limit=20, p=0.5, border_mode=cv2.BORDER_CONSTANT\n",
    "#                                     ),\n",
    "#                                     A.IAAAffine(shear=15, p=0.5, mode=\"constant\"),\n",
    "#                                 ],\n",
    "#                                 p=1.0,\n",
    "#                             ),\n",
    "#                             A.HorizontalFlip(p=0.5),\n",
    "#                             A.Blur(p=0.1),\n",
    "#                             A.CLAHE(p=0.1),\n",
    "#                             A.Posterize(p=0.1),\n",
    "#                             A.ToGray(p=0.1),\n",
    "#                             A.ChannelShuffle(p=0.05),\n",
    "                            A.Normalize(mean=[0, 0, 0], std=[1, 1, 1], max_pixel_value=255,),\n",
    "                            #A.Normalize(mean=MEAN, std=STD, max_pixel_value=255,),\n",
    "                            ToTensorV2(),\n",
    "                        ]),\n",
    "    \n",
    "                'val3': transforms.Compose([\n",
    "#                       transforms.Resize(input_size),\n",
    "#                     transforms.Scale(SIZE),\n",
    "                      ResizeLargerSide(int(RESIZE_RATIO*SIZE)),\n",
    "                      RandomPad(SIZE),                           # we have to add this\n",
    "#                       transforms.Pad(SIZE//2, 255),\n",
    "                      transforms.RandomGrayscale(p=0.01),\n",
    "                      #transforms.RandomHorizontalFlip(p=0.5),\n",
    "                      transforms.RandomAffine(degrees=2, translate=(.2, .2), scale=(0.5, 1), \n",
    "                                              fillcolor=(114, 114, 114),shear=(-0.3, 0.3, -0.3, 0.3)),\n",
    "#                       transforms.RandomAffine(degrees=1, translate=(.2, .2), scale=(1 / 1.5, 1.5),\n",
    "#                                           shear=(-1, 1, -1, 1)),\n",
    "                      transforms.ToTensor(),\n",
    "                    # TenCrop didn't provide a variety of images. with bare eyes, they were identical,\n",
    "                    # there were 5 of them identical to each other and another 5 flipped horizontally\n",
    "#                       transforms.TenCrop(input_size),\n",
    "#                       transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "#                       transforms.Lambda(lambda normal: torch.stack([transforms.Normalize(MEAN, STD)(normalize) for normalize in normal]))                      \n",
    "                 ]),\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_loader(path):\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')\n",
    "\n",
    "def idx2class(idx):\n",
    "    return index_to_class[index_to_class['index']==idx]['class'][idx]\n",
    "\n",
    "n_TTA=32\n",
    "def extend_labels(label):\n",
    "    return [label for x in range(n_TTA)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.io as io\n",
    "# img_path = '../data/test/singles/MA160865191500037.005-K_11_1_.png'\n",
    "img_path = '../data/test/singles/MA1867826.002-K_1_1_.png'\n",
    "image_m = pil_loader(img_path)  # image_m = PIL.Image.Image\n",
    "# image_io = io.imread(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119, 382)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(image_m)\n",
    "image_m.size   # (69, 166)   (119, 382) = (width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "transform = data_transforms_augmentation['val4']\n",
    "image_t = transform(image_m)   # image_t = torch.Tensor\n",
    "#image2=transforms.functional.autocontrast(image2)\n",
    "image_t = image_t.permute(1, 2, 0)\n",
    "#image2 = image2.to('cpu')\n",
    "#image2 = image2.detach().numpy()\n",
    "# input_s.shape\n",
    "plt.imshow(image_t, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ****** IF we use \"albumentations\" for transformations: ***********\n",
    "transform = data_transforms_augmentation['albumentations']\n",
    "image_arr = np.asarray(image_m)   # image_arr = numpy.ndarray\n",
    "image_t = transform(image=image_arr)  # image_t = torch.Tensor\n",
    "# image_t = transform(image=image_m)   # fails, can't accept PIL type for transformation\n",
    "image_t = image_t['image'].permute(1, 2, 0)\n",
    "plt.imshow(image_t, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ****** IF we use \"albumentations\" for transformations: ***********\n",
    "transform = data_transforms_augmentation['albumentations']\n",
    "image_arr = np.asarray(image_m)   # image_arr = numpy.ndarray\n",
    "image_t = transform(image=image_arr)  # image_t = torch.Tensor\n",
    "# image_t = transform(image=image_m)   # fails, can't accept PIL type for transformation\n",
    "image_t = image_t['image'].permute(1, 2, 0)\n",
    "plt.imshow(image_t, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-30 20:16:13,418  train_ppt   INFO  self.device: cpu\n",
      "2021-05-30 20:16:13,418  train_ppt   INFO  self.device: cpu\n",
      "2021-05-30 20:16:13,544  train_ppt   INFO  model in use: densenet121\n",
      "2021-05-30 20:16:13,544  train_ppt   INFO  model in use: densenet121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date and time = 30.05.2021_20.16.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.img_dir: ../data/test/singles/\n",
      "annotations_file: ../data/test_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/64 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 1/64 [00:05<05:51,  5.58s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_SM: 0.9993904829025269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  3%|▎         | 2/64 [00:10<05:29,  5.32s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_SM: 0.830894947052002\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-c63a3fbc7279>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;31m#print(f'2: {datetime.now()}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0moutputs1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# outputs1 = torch.Tensor = torch.Size([32, 24])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0moutputs2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;31m# outputs2 = torch.Tensor = torch.Size([32, 24])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0moutputs3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# outputs3 = numpy.ndarray = (32, 24)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torchvision/models/densenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madaptive_avg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torchvision/models/densenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, init_features)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minit_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mnew_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torchvision/models/densenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mbottleneck_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mnew_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbottleneck_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_rate\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             new_features = F.dropout(new_features, p=self.drop_rate,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 420\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_date=datetime.now()\n",
    "config_path = '../config/config_densenet121_TTA.ini'\n",
    "config = ConfigParser()\n",
    "config.read(config_path)\n",
    "l_pictures = []; l_outputs = []; l_labels = []\n",
    "\n",
    "root_dir = config.get('model', 'root_dir')\n",
    "data_dir = data_dir = config.get('data', 'data_dir')\n",
    "model_list = {config.get('model', 'name')} \n",
    "num_classes = config.getint('model', 'num_classes')\n",
    "batch_size = config.getint('model', 'batch_size')\n",
    "shuffle = config.getboolean('data', 'shuffle')\n",
    "t_data_set = config.get('test', 't_data_set')          # 'test' or 'val_test'\n",
    "single_channel = config.getboolean('model', 'single_channel')\n",
    "model_meta_csv = config.get('test', 'model_meta_csv') \n",
    "test_data_csv = f'{root_dir}data/test_data.csv'\n",
    "data_transform = config.get('data', 'transform')\n",
    "\n",
    "torch.manual_seed(config.getint('data', 'seed'))\n",
    "np.random.seed(config.getint('data', 'seed'))\n",
    "\n",
    "dops1 = do.dops(config)\n",
    "\n",
    "pre_model_test = ppm.pt_model(config)\n",
    "model_test, input_size = pre_model_test.initialize()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dops1.pick_data_transforms(data_transform, pre_model_test.input_size)\n",
    "#model_test.load_state_dict(torch.load('../models/dir_densenet121/densenet121_11epochs_0.9566.weights', map_location=device))\n",
    "model_path = '../models/dir_densenet121/albumentations1/densenet121_31epochs_0.9538.weights'\n",
    "model_test.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model_test.eval()\n",
    "\n",
    "if device == 'cpu':\n",
    "    model_test.cpu()\n",
    "\n",
    "test_dataset = cds.MyImageDataset(config, dops1, t_data_set = t_data_set)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "option=2 # [0, 1, 2] = [single_input, multiple_input, multiply_single_input]\n",
    "aug_tst = 0; #n_TTA = 1\n",
    "transform_type = 'albumentations'  #'val4'\n",
    "transform = data_transforms_augmentation[transform_type]\n",
    "# [picture, image, label_idx, str(label)]\n",
    "for pictures, inputs, _, labels in tqdm(test_dataloader):     \n",
    "    inputs = inputs.to(device)              # inputs = torch.Tensor = torch.Size([64, 3, 224, 224])\n",
    "\n",
    "    if option == 0:\n",
    "        outputs = model_test(inputs)        # outputs1 = torch.Tensor = torch.Size([64, 24])\n",
    "        outputs = outputs.to('cpu')         # outputs2 = torch.Tensor = torch.Size([64, 24])\n",
    "        outputs = outputs.detach().numpy()  # outputs3 = numpy.ndarray = (64, 24)\n",
    "\n",
    "        l_pictures.extend(pictures)\n",
    "\n",
    "        l_outputs.extend(outputs)\n",
    "        l_labels.extend(labels)\n",
    "        \n",
    "        if aug_tst == 0:\n",
    "            break\n",
    "        aug_tst += 1\n",
    "    \n",
    "    elif option == '0.in':\n",
    "        outputs = model_test(inputs)        # outputs1 = torch.Tensor = torch.Size([64, 24])\n",
    "        outputs = outputs.to('cpu')         # outputs2 = torch.Tensor = torch.Size([64, 24])\n",
    "        outputs = outputs.detach().numpy()  # outputs3 = numpy.ndarray = (64, 24)\n",
    "\n",
    "        l_pictures.extend(pictures)\n",
    "\n",
    "        l_outputs.extend(outputs)\n",
    "        l_labels.extend(labels)\n",
    "        \n",
    "        if aug_tst == 0:\n",
    "            break\n",
    "        aug_tst += 1\n",
    "        \n",
    "    elif option == 1:\n",
    "        for i in range(n_TTA):\n",
    "            #single_input = inputs[:, i, ...]\n",
    "            single_input = inputs\n",
    "            outputs1 = model_test(single_input)   \n",
    "            outputs2 = outputs1.to('cpu')\n",
    "            outputs3 = outputs2.detach().numpy()\n",
    "\n",
    "            l_pictures.extend(pictures)\n",
    "\n",
    "            l_outputs.extend(outputs)\n",
    "            l_labels.extend(labels)\n",
    "    elif option == 2:\n",
    "        '''\n",
    "        for i in tqdm(range(len(labels))):\n",
    "            np_output_single = np.zeros([1, 24])\n",
    "            img_path = f'../data/test/singles/{pictures[i]}'\n",
    "            image = pil_loader(img_path)\n",
    "            image_arr = np.asarray(image)\n",
    "            for j in range(n_TTA):                \n",
    "                single_input = transform(image=image_arr)\n",
    "                single_input = single_input['image']\n",
    "                \n",
    "                output_single = model_test(single_input.reshape([1, 3, 224, 224]))\n",
    "                output_single = output_single.to('cpu')\n",
    "                output_single = output_single.detach().numpy()\n",
    "                #output_single = softmax(output_single)\n",
    "                np_output_single += output_single\n",
    "                \n",
    "            l_pictures.append(pictures[i])\n",
    "            #l_outputs.extend(np_output_single/n_TTA)\n",
    "            l_outputs.extend(np_output_single/n_TTA)\n",
    "            l_labels.append(labels[i])\n",
    "            \n",
    "        ######################################################\n",
    "        for i in tqdm(range(len(labels))):\n",
    "            np_output_single = np.zeros([1, 24])\n",
    "            img_path = f'../data/test/singles/{pictures[i]}'\n",
    "            image = pil_loader(img_path)\n",
    "            if transform_type == 'albumentations':\n",
    "                image_arr = np.asarray(image)\n",
    "            for j in range(n_TTA):                \n",
    "                if transform_type == 'albumentations':\n",
    "                    single_input = transform(image=image_arr)\n",
    "                    single_input = single_input['image']\n",
    "                else:\n",
    "                    single_input = transform(image)\n",
    "                \n",
    "                output_single = model_test(single_input.reshape([1, 3, 224, 224]))\n",
    "                output_single = output_single.to('cpu')\n",
    "                output_single = output_single.detach().numpy()\n",
    "                #output_single = softmax(output_single)\n",
    "                np_output_single += output_single\n",
    "                \n",
    "            l_pictures.append(pictures[i])\n",
    "            #l_outputs.extend(np_output_single/n_TTA)\n",
    "            l_outputs.extend(np_output_single/n_TTA)\n",
    "            l_labels.append(labels[i])\n",
    "        \n",
    "        ####################################################\n",
    "        \n",
    "\n",
    "        for i in tqdm(range(len(labels))):\n",
    "            #print(f'1: {datetime.now()}')\n",
    "            np_output_single = np.zeros([1, 24])\n",
    "            #img_path = f'{dir_test_data}{pictures[i]}'\n",
    "            img_path = f'../data/test/singles/{pictures[i]}'\n",
    "            image = pil_loader(img_path)\n",
    "            #print(f'2: {datetime.now()}')\n",
    "            if transform_type == 'albumentations':\n",
    "                image_arr = np.asarray(image)\n",
    "            #print(f'3: {datetime.now()}')\n",
    "            l_output = []\n",
    "            for j in range(n_TTA):\n",
    "                if transform_type == 'albumentations':\n",
    "                    #print(f'4: {datetime.now()}')\n",
    "                    single_input = transform(image=image_arr)\n",
    "                    single_input = single_input['image']\n",
    "                    if j == 0:\n",
    "                        # type: <class 'torch.Tensor'> shape: torch.Size([2, 3, 224, 224])\n",
    "                        t_stack = torch.stack([single_input, single_input])\n",
    "                        #print(f't_stack1... type: {type(t_stack)} shape: {t_stack.shape}')\n",
    "                    else:\n",
    "                        # type: <class 'torch.Tensor'> shape: torch.Size([3, 3, 224, 224])\n",
    "                        t_stack = torch.cat([t_stack, single_input.reshape([1, 3, 224, 224])], dim=0)\n",
    "                        #print(f't_stack2... type: {type(t_stack)} shape: {t_stack.shape}')\n",
    "\n",
    "                    t_stack = t_stack.to(device)  \n",
    "                else:\n",
    "                    single_input = transform(image)\n",
    "\n",
    "                #print(f'5: {datetime.now()}')\n",
    "                #output_single = model_test(single_input.reshape([1, 3, 224, 224]))\n",
    "                #output_single = output_single.to('cpu')\n",
    "                #output_single = output_single.detach().numpy()\n",
    "                #output_single = softmax(output_single)\n",
    "                #np_output_single += output_single\n",
    "\n",
    "            t_stack = t_stack[1:, ...]              # torch.Size([32, 3, 224, 224])\n",
    "            outputs1 = model_test(t_stack)          # outputs1 = torch.Tensor = torch.Size([32, 24])\n",
    "            outputs2 = outputs1.to('cpu')           # outputs2 = torch.Tensor = torch.Size([32, 24])\n",
    "            outputs3 = outputs2.detach().numpy()    # outputs3 = numpy.ndarray = (32, 24) \n",
    "            #outputs4 = softmax(outputs3)           # outputs4 = numpy.ndarray = (32, 24)\n",
    "            mean_outputs = np.mean(outputs3, axis=0) # mean_outputs = numpy.ndarray = (24,)\n",
    "\n",
    "            #print(f'6: {datetime.now()}')\n",
    "            l_pictures.append(pictures[i])\n",
    "            #l_outputs.extend(np_output_single/n_TTA)\n",
    "            l_outputs.append(mean_outputs)\n",
    "            l_labels.append(labels[i])\n",
    "        '''\n",
    "        #########################################################\n",
    "        ### ONLY for Albumentations TTA  ## working fine but takes too much time to compute!\n",
    "        for i in tqdm(range(len(labels))):\n",
    "            #print(f'1: {datetime.now()}')\n",
    "            #img_path = f'{dir_test_data}{pictures[i]}'\n",
    "            #print(f'2: {datetime.now()}')\n",
    "\n",
    "            outputs1 = model_test(inputs[i])        # outputs1 = torch.Tensor = torch.Size([32, 24])\n",
    "            outputs2 = outputs1.to('cpu')           # outputs2 = torch.Tensor = torch.Size([32, 24])\n",
    "            outputs3 = outputs2.detach().numpy()    # outputs3 = numpy.ndarray = (32, 24) \n",
    "#             outputs4 = softmax(outputs3)           # outputs4 = numpy.ndarray = (32, 24)\n",
    "#             mean_outputs = np.mean(outputs4, axis=0)    # mean_outputs = numpy.ndarray = (24,)      \n",
    "            outputs4 = [softmax(output) for output in outputs3] # outputs4=list of 32 arrays with the size (24,)\n",
    "            mean_outputs = np.mean(outputs4, axis=0)    # mean_outputs = numpy.ndarray = (24,) \n",
    "            print(f'max_SM: {mean_outputs[np.argmax(mean_outputs)]}')\n",
    "\n",
    "#             mean_outputs = np.mean(outputs3, axis=0)    # mean_outputs = numpy.ndarray = (24,)\n",
    "\n",
    "            #print(f'6: {datetime.now()}')\n",
    "            l_pictures.append(pictures[i])\n",
    "            #l_outputs.extend(np_output_single/n_TTA)\n",
    "            l_outputs.append(mean_outputs)\n",
    "#             l_outputs.append(softmax(mean_outputs))\n",
    "            l_labels.append(labels[i])\n",
    "        \n",
    "            \n",
    "#             if aug_tst == 0:\n",
    "#                 break\n",
    "    \n",
    "        if aug_tst == 0:\n",
    "            break\n",
    "        aug_tst += 1\n",
    "    \n",
    "    # this one crashes the memory.. works ok with 8 batches and 32 TTA images\n",
    "    elif option == 3:\n",
    "        l_extended_labels = []\n",
    "        l_extended_pictures = []\n",
    "        for i in range(len(labels)):\n",
    "            l_extended_labels.extend(extend_labels(labels[i]))\n",
    "            l_extended_pictures.extend(extend_labels(pictures[i]))\n",
    "        \n",
    "        #outputs1 = model_test(inputs)\n",
    "        n_batch = 8 # 64\n",
    "        n_TTA = 32\n",
    "        outputs1 = model_test(inputs.reshape([n_batch*n_TTA, 3, 224, 224]))        \n",
    "        outputs2 = outputs1.to('cpu')\n",
    "        outputs3 = outputs2.detach().numpy()\n",
    "        outputs4 = [softmax(output) for output in outputs3]\n",
    "        \n",
    "        l_pictures.extend(l_extended_pictures)\n",
    "        l_outputs.extend(outputs4)\n",
    "        l_labels.extend(l_extended_labels)\n",
    "    \n",
    "        if aug_tst == 0:\n",
    "            break\n",
    "        aug_tst += 1\n",
    "    \n",
    "\n",
    "        \n",
    "print('done')\n",
    "print(f'total_time: {datetime.now()-start_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_extended_labels = []\n",
    "for label in labels:\n",
    "    l_extended_labels.extend(extend_labels(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_extended_labels = []\n",
    "l_extended_pictures = []\n",
    "for i in range(len(labels)):\n",
    "    l_extended_labels.extend(extend_labels(labels[i]))\n",
    "    l_extended_pictures.extend(extend_labels(pictures[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l_extended_pictures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.mean(outputs3, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't_stack' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-bd80a5010010>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 't_stack' is not defined"
     ]
    }
   ],
   "source": [
    "# t_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l_pictures: ['MA1867826.096-K_16_1_.png', 'MA160865191500027.022-K_22_0_.png', 'MA160873676300031.017-K_22_1_.png', 'MA160873676300027.006-K_19_0_.png', 'MA160873676300043.124-K_18_1_.png', 'MA160873676300041.009-K_2_0_.png', 'MA160865191500021.019-K_9_1_.png', 'MA1867835.028-K_4_1_.png', 'MA160873676300016.101-K_20_1_.png', 'MA160865191500002.004-K_9_1_.png', 'MA160865191500015.006-K_9_1_.png', 'MA160873676300039.018-K_1_1_.png', 'MA1867833.023-K_21_0_.png', 'MA160873676300027.017-K_21_1_.png', 'MA160873676300028.007-K_11_1_.png', 'MA641141867832.070-K_7_0_.png', 'MA160865191500046.018-K_20_1_.png', 'MA160873676300003.074-K_5_1_.png', 'MA160814197500038.056-K_10_0_.png', 'MA1867835.042-K_21_1_.png', 'MA160873676300039.003-K_10_1_.png', 'MA160814197500062.003-K_1_0_.png', 'MA160814197500059.065-K_4_0_.png', 'MA160873676300019.015-K_11_0_.png', 'MA160873676300003.014-K_2_1_.png', 'MA160873676300003.004-K_10_0_.png', 'MA160814197500043.008-K_10_0_.png', 'MA160814197500062.003-K_14_1_.png', 'MA160873676300016.038-K_22_1_.png', 'MA1867826.007-K_19_0_.png', 'MA1867833.008-K_21_0_.png', 'MA160873676300031.010-K_8_1_.png', 'MA160814197500026.041-K_10_0_.png', 'MA1867833.245-K_8_1_.png', 'MA160814197500043.008-K_13_1_.png', 'MA160873676300027.006-K_18_1_.png', 'MA160873676300028.011-K_5_1_.png', 'MA160814197500059.032-K_2_1_.png', 'MA1867835.104-K_1_1_.png', 'MA160865191500027.009-K_4_0_.png', 'MA160865191500015.016-K_12_0_.png', 'MA1867829.082-K_6_1_.png', 'MA160814197500040.020-K_18_0_.png', 'MA160814197500038.069-K_8_1_.png', 'MA160865191500037.004-K_19_0_.png', 'MA160865191500021.004-K_x_0_.png', 'MA1867826.014-K_x_0_.png', 'MA160814197500041.062-K_4_0_.png', 'MA160814197500042.017-K_8_1_.png', 'MA160873676300003.074-K_18_1_.png', 'MA160865191500046.017-K_18_0_.png', 'MA160814197500043.086-K_x_1_.png', 'MA160865191500015.016-K_x_1_.png', 'MA160814197500004.081-K_16_0_.png', 'MA1867833.026-K_y_0_.png', 'MA1867829.038-K_13_0_.png', 'MA160814197500026.041-K_17_1_.png', 'MA1867826.014-K_18_0_.png', 'MA1867826.099-K_19_1_.png', 'MA160865191500002.033-K_19_1_.png', 'MA160814197500059.034-K_13_0_.png', 'MA160873676300043.020-K_14_1_.png', 'MA1867826.026-K_3_1_.png', 'MA1867826.006-K_4_1_.png'], l_outputs: [array([3.5324312e-05, 6.0462474e-07, 3.2888158e-04, 2.2049683e-06,\n",
      "       1.1205888e-05, 3.3411952e-06, 4.4207023e-05, 7.1241702e-05,\n",
      "       7.2318406e-05, 1.0095865e-05, 2.3107229e-04, 2.0559990e-05,\n",
      "       3.0163804e-03, 5.6262263e-05, 1.4467615e-05, 9.9072838e-01,\n",
      "       2.6835633e-06, 1.5642020e-03, 3.0676284e-04, 9.9338213e-05,\n",
      "       6.6383468e-04, 7.5613457e-04, 1.8034215e-03, 1.5703084e-04],\n",
      "      dtype=float32), array([1.2670270e-04, 2.5248967e-04, 2.4213789e-04, 4.4371519e-04,\n",
      "       1.3202455e-04, 2.2828230e-04, 4.8788716e-04, 2.7513102e-05,\n",
      "       4.9940177e-04, 1.5106768e-04, 7.7717363e-05, 1.8130631e-04,\n",
      "       2.1694809e-04, 6.1028064e-03, 4.3828557e-03, 4.3526888e-04,\n",
      "       1.3275477e-03, 1.1627050e-04, 4.0953279e-02, 4.4687656e-03,\n",
      "       3.4685001e-02, 9.0387809e-01, 3.2854051e-04, 2.5438593e-04],\n",
      "      dtype=float32), array([9.8804067e-06, 3.4872196e-06, 7.5793514e-07, 9.8104259e-08,\n",
      "       4.2403047e-07, 2.6433995e-07, 1.7318976e-06, 2.5765228e-08,\n",
      "       3.6057504e-06, 8.0585851e-06, 5.6678317e-07, 1.4196896e-05,\n",
      "       2.6292573e-08, 7.0938008e-06, 6.1708101e-07, 1.7684471e-06,\n",
      "       4.1296196e-05, 5.7820290e-07, 5.4966399e-06, 8.5464608e-06,\n",
      "       4.4505799e-05, 9.9974024e-01, 1.3203551e-06, 1.0561438e-04],\n",
      "      dtype=float32), array([4.2241703e-05, 2.2520554e-07, 6.2834051e-06, 5.0963658e-06,\n",
      "       5.6826084e-06, 1.4855118e-06, 1.3884895e-05, 2.7483215e-06,\n",
      "       7.2485062e-07, 2.1199157e-05, 1.7133552e-04, 1.1410010e-05,\n",
      "       2.4064529e-05, 2.1570240e-05, 1.4158420e-04, 2.7140239e-02,\n",
      "       1.1405145e-05, 1.9221359e-04, 9.7074294e-01, 5.9850904e-04,\n",
      "       1.3473070e-04, 5.6569226e-04, 1.3857658e-04, 6.0349380e-06],\n",
      "      dtype=float32), array([9.9608455e-09, 2.1235327e-09, 2.3835643e-08, 1.1118382e-09,\n",
      "       8.4846628e-09, 2.1998375e-08, 1.1701765e-07, 5.7507807e-09,\n",
      "       1.8944635e-09, 3.3250828e-07, 2.3441899e-07, 3.1715825e-08,\n",
      "       6.9918342e-09, 1.8452067e-08, 1.5264770e-07, 6.3178982e-07,\n",
      "       6.8979240e-08, 9.9999803e-01, 3.6283518e-07, 3.7875093e-08,\n",
      "       3.8417529e-08, 1.3391588e-08, 6.3344263e-09, 1.7496436e-07],\n",
      "      dtype=float32), array([1.8173349e-05, 9.9993986e-01, 6.6231621e-07, 8.5083111e-06,\n",
      "       1.0668292e-06, 9.0841768e-06, 2.4938720e-06, 4.1554845e-06,\n",
      "       4.0009986e-06, 9.5758628e-07, 4.4709995e-07, 2.3053217e-07,\n",
      "       6.7580204e-06, 8.1431102e-07, 1.2497318e-08, 1.7315525e-08,\n",
      "       1.6298346e-06, 4.4829317e-08, 2.7974698e-09, 5.3288214e-09,\n",
      "       5.0207456e-09, 1.2305992e-08, 9.4419050e-07, 1.8985927e-08],\n",
      "      dtype=float32), array([3.1529763e-07, 3.5216839e-05, 3.6567232e-07, 1.0270088e-05,\n",
      "       2.1470318e-07, 8.2893692e-08, 8.7072033e-07, 6.5384819e-03,\n",
      "       9.9264264e-01, 1.3812423e-04, 5.1667932e-05, 2.6687114e-06,\n",
      "       5.2968954e-04, 2.5617534e-05, 3.3624079e-07, 8.1830322e-06,\n",
      "       1.4320844e-06, 2.1868796e-06, 1.8247187e-08, 7.6020177e-07,\n",
      "       1.3904396e-07, 8.7028596e-08, 1.0322329e-05, 4.8362955e-07],\n",
      "      dtype=float32), array([4.9842928e-08, 5.9739045e-09, 9.6461261e-10, 9.9999970e-01,\n",
      "       4.9706563e-07, 1.6189902e-09, 1.2153463e-09, 1.1200578e-09,\n",
      "       1.2489537e-09, 2.4116617e-10, 3.8256913e-09, 8.2150491e-09,\n",
      "       2.8496987e-09, 7.3162976e-10, 1.5410881e-10, 2.1433279e-11,\n",
      "       1.6196630e-10, 2.1150828e-11, 6.2783417e-10, 1.7244005e-10,\n",
      "       2.5513121e-11, 7.4603613e-12, 5.5303064e-09, 2.0971133e-10],\n",
      "      dtype=float32), array([1.6161589e-06, 2.6995158e-07, 1.6560417e-08, 1.3878753e-06,\n",
      "       8.5492871e-07, 1.9051775e-07, 3.7422422e-05, 6.0742752e-07,\n",
      "       5.7610091e-06, 7.1176231e-07, 1.6387449e-06, 3.7294575e-07,\n",
      "       5.4354331e-07, 3.4915789e-05, 1.1404192e-06, 8.1319467e-06,\n",
      "       2.4343460e-06, 1.7121787e-06, 1.9182746e-06, 9.9988914e-01,\n",
      "       4.9469139e-07, 1.9567440e-06, 5.7755767e-07, 6.2295453e-06],\n",
      "      dtype=float32), array([1.6205297e-05, 6.0464539e-05, 1.5134251e-05, 6.5029488e-04,\n",
      "       1.6920558e-04, 9.3734590e-05, 9.0771460e-04, 2.6879628e-04,\n",
      "       9.8725849e-01, 2.5347911e-03, 9.2575057e-05, 4.5600356e-04,\n",
      "       9.3812887e-05, 7.5110831e-05, 5.9073358e-05, 2.0359458e-04,\n",
      "       1.1033891e-03, 4.0113933e-05, 1.5330696e-05, 1.5062997e-03,\n",
      "       1.0053087e-04, 5.9626746e-04, 3.8720991e-05, 3.6443574e-03],\n",
      "      dtype=float32), array([1.9819484e-07, 2.9084737e-05, 3.4930315e-07, 1.0196853e-05,\n",
      "       4.1034068e-06, 6.1649444e-06, 1.3892632e-07, 9.9636003e-05,\n",
      "       9.9938351e-01, 3.1985616e-04, 2.3660298e-06, 6.8016388e-06,\n",
      "       9.3353719e-07, 9.6583419e-05, 2.7394708e-07, 7.1557761e-06,\n",
      "       2.7273456e-05, 5.1106198e-08, 1.4537981e-07, 6.4102034e-07,\n",
      "       1.4599177e-06, 2.8679174e-06, 2.2718847e-07, 8.4834980e-08],\n",
      "      dtype=float32), array([9.99996543e-01, 3.70718169e-07, 3.60993901e-08, 8.35288674e-08,\n",
      "       2.46347611e-07, 9.52718651e-08, 1.35557855e-07, 7.40826636e-08,\n",
      "       9.49919521e-09, 9.20783023e-08, 2.47247129e-07, 1.01523405e-07,\n",
      "       2.86968429e-07, 8.70869542e-07, 1.42354196e-07, 2.08977909e-07,\n",
      "       5.92593317e-08, 2.73905307e-08, 2.15524771e-08, 3.85438614e-09,\n",
      "       3.67855879e-09, 2.12958029e-09, 3.69976902e-07, 2.28034969e-09],\n",
      "      dtype=float32), array([3.2609867e-05, 3.0455747e-06, 1.8706021e-05, 6.3768498e-06,\n",
      "       4.2927972e-05, 2.9645050e-06, 5.8782771e-06, 1.4943582e-06,\n",
      "       3.9077013e-06, 8.1914141e-06, 1.5807962e-04, 2.6512356e-05,\n",
      "       1.4639058e-05, 1.1385046e-04, 2.5794262e-04, 1.1820661e-05,\n",
      "       3.4882749e-05, 4.6767871e-04, 1.0969880e-03, 6.2716936e-05,\n",
      "       9.9751955e-01, 7.5075128e-05, 1.2062557e-05, 2.2195591e-05],\n",
      "      dtype=float32), array([7.1275594e-05, 1.3100824e-05, 2.8094125e-06, 3.6968588e-05,\n",
      "       5.2956988e-05, 1.2438427e-05, 8.3194545e-06, 3.2503769e-05,\n",
      "       5.0998337e-06, 4.1866384e-04, 1.1363618e-04, 2.7398800e-04,\n",
      "       3.5589605e-05, 6.9016713e-04, 5.4200500e-04, 7.8428151e-05,\n",
      "       5.7441244e-05, 1.7479924e-04, 1.4973443e-03, 4.5620607e-05,\n",
      "       9.9532610e-01, 4.1609508e-04, 6.2304978e-05, 3.2288193e-05],\n",
      "      dtype=float32), array([2.6353646e-06, 2.4786735e-07, 7.4826039e-07, 5.9698878e-06,\n",
      "       3.1685349e-07, 2.6388994e-08, 3.6264228e-07, 9.3169113e-08,\n",
      "       3.4853356e-06, 1.0960780e-06, 9.9993277e-01, 1.9320079e-05,\n",
      "       1.1996987e-06, 5.1016872e-07, 1.9974207e-06, 2.1073707e-07,\n",
      "       1.7246146e-05, 9.3151448e-07, 5.6791328e-07, 6.2592915e-07,\n",
      "       3.8643307e-06, 5.5008277e-06, 2.5304431e-07, 3.7262676e-08],\n",
      "      dtype=float32), array([5.7718319e-07, 5.7261844e-09, 1.4634989e-09, 2.5844916e-08,\n",
      "       6.4156694e-07, 4.8186322e-09, 9.9999660e-01, 2.0706979e-07,\n",
      "       7.4914816e-08, 8.7364299e-07, 1.8569722e-08, 1.6451420e-07,\n",
      "       3.3464218e-07, 2.2259261e-08, 3.3978928e-08, 2.6909087e-08,\n",
      "       1.5441989e-08, 1.0293401e-07, 1.5119932e-09, 2.5318548e-07,\n",
      "       5.6249144e-10, 7.3316757e-09, 3.7324078e-08, 2.7713947e-08],\n",
      "      dtype=float32), array([1.4172592e-08, 3.7054632e-10, 5.6542299e-10, 1.2251404e-06,\n",
      "       4.6894460e-08, 2.4962181e-09, 2.1698585e-07, 1.0264969e-09,\n",
      "       9.5871409e-09, 5.0146542e-07, 1.6567667e-07, 7.3967087e-08,\n",
      "       1.6125692e-07, 9.1941388e-08, 2.1033129e-06, 2.7849217e-07,\n",
      "       7.4802493e-09, 6.8279968e-09, 2.1402593e-05, 9.9997312e-01,\n",
      "       2.2261078e-08, 2.7492590e-07, 5.7406037e-08, 3.6527968e-08],\n",
      "      dtype=float32), array([8.9998437e-08, 2.0745686e-07, 1.2099227e-06, 8.2391189e-06,\n",
      "       9.9997503e-01, 3.6228784e-09, 4.6343953e-06, 3.4638720e-07,\n",
      "       1.7944285e-06, 9.8488442e-08, 3.3824026e-07, 3.8327025e-06,\n",
      "       5.8271968e-07, 7.3710360e-08, 4.7755918e-07, 1.4272537e-08,\n",
      "       1.0199616e-06, 9.7530847e-07, 4.6523045e-08, 9.4345182e-08,\n",
      "       2.7156370e-08, 5.3936486e-08, 9.1775320e-07, 3.5534885e-08],\n",
      "      dtype=float32), array([6.4264881e-08, 5.0364253e-07, 2.5779284e-08, 2.6780506e-07,\n",
      "       6.5536796e-08, 2.9858717e-07, 9.0878319e-07, 8.9335322e-07,\n",
      "       3.8901668e-05, 9.9995029e-01, 1.0148356e-07, 1.8828500e-07,\n",
      "       1.9198640e-06, 6.8828740e-07, 5.8053764e-08, 2.0278917e-06,\n",
      "       7.3571613e-08, 2.1285828e-06, 2.2250877e-08, 4.9828219e-07,\n",
      "       2.6375119e-08, 4.8828571e-08, 8.6139003e-08, 1.3466897e-08],\n",
      "      dtype=float32), array([2.8130728e-07, 5.8071169e-08, 8.0111732e-08, 2.2239635e-07,\n",
      "       2.9131004e-07, 2.1536810e-07, 1.3733153e-07, 2.6196864e-07,\n",
      "       6.3414241e-08, 1.5109597e-06, 3.3862368e-06, 5.3488820e-06,\n",
      "       2.5117054e-06, 2.7089522e-05, 4.6575769e-06, 1.3968888e-06,\n",
      "       1.6385251e-06, 1.3350290e-06, 5.2135758e-05, 1.5543596e-06,\n",
      "       9.9985969e-01, 2.8956509e-05, 1.0774365e-06, 6.0221682e-06],\n",
      "      dtype=float32), array([4.90464949e-08, 1.54506310e-07, 2.65132236e-08, 2.60730744e-08,\n",
      "       3.76410618e-08, 8.32988178e-07, 1.61410668e-07, 4.40461662e-07,\n",
      "       5.20977835e-07, 9.99996483e-01, 9.79952208e-09, 4.27494626e-08,\n",
      "       9.34837701e-08, 1.29650335e-08, 1.93006038e-08, 1.01732792e-06,\n",
      "       9.91937821e-09, 1.34237041e-07, 4.28088995e-08, 1.21977983e-08,\n",
      "       1.82752142e-08, 2.75108718e-08, 3.45639997e-08, 3.14534265e-09],\n",
      "      dtype=float32), array([9.9983597e-01, 1.1858112e-05, 2.5712770e-05, 1.6845155e-05,\n",
      "       2.4346074e-05, 1.0972500e-05, 3.3915640e-06, 2.9178997e-07,\n",
      "       4.7568932e-08, 1.2511599e-06, 3.3663582e-06, 8.8218576e-07,\n",
      "       1.0778366e-05, 1.4580428e-06, 1.6607846e-05, 3.3713256e-06,\n",
      "       2.0595112e-06, 1.4259062e-06, 2.9099240e-06, 1.2043819e-07,\n",
      "       2.0719753e-07, 8.7141494e-08, 2.5960360e-05, 2.3291501e-07],\n",
      "      dtype=float32), array([1.5665503e-04, 2.0681025e-02, 4.3121990e-04, 9.2557424e-01,\n",
      "       1.4450982e-02, 3.5089170e-04, 1.1812306e-04, 6.7861853e-03,\n",
      "       1.4251021e-02, 6.7533756e-04, 2.9606041e-03, 1.8689649e-03,\n",
      "       1.1053478e-03, 7.2819658e-04, 2.0418707e-03, 7.0953488e-06,\n",
      "       4.5176261e-04, 1.6259303e-04, 3.8723028e-05, 2.0054435e-05,\n",
      "       1.9375717e-05, 2.3403014e-05, 6.9442810e-03, 1.5211159e-04],\n",
      "      dtype=float32), array([3.5524133e-07, 1.5793451e-06, 1.1647381e-06, 2.7465445e-05,\n",
      "       7.8158155e-06, 3.2278262e-08, 1.9961142e-07, 1.0207038e-06,\n",
      "       5.7130394e-05, 1.6432921e-06, 9.9985230e-01, 2.4443005e-05,\n",
      "       5.5229191e-07, 1.0777460e-06, 2.5983722e-06, 8.5196189e-07,\n",
      "       7.9337296e-06, 5.1378020e-06, 5.1646975e-07, 6.0972917e-07,\n",
      "       2.3650571e-06, 1.9973700e-06, 1.0265110e-06, 1.5774947e-07],\n",
      "      dtype=float32), array([6.92719041e-05, 9.98735785e-01, 5.27769334e-05, 1.31332068e-04,\n",
      "       1.89553946e-04, 3.15291873e-05, 7.03675641e-06, 1.85558703e-04,\n",
      "       3.87992972e-04, 1.66499685e-05, 1.82172116e-05, 1.14741556e-06,\n",
      "       5.79805273e-05, 1.25310851e-06, 1.64038511e-07, 3.32293467e-07,\n",
      "       1.34183847e-06, 4.72163464e-08, 4.96455243e-07, 8.26999980e-08,\n",
      "       1.33614449e-07, 3.96228387e-07, 1.10553636e-04, 2.91538299e-07],\n",
      "      dtype=float32), array([7.9364977e-09, 7.9080866e-09, 1.0321874e-09, 4.7021897e-09,\n",
      "       1.3919529e-09, 1.2358608e-08, 2.0469470e-06, 4.9008730e-07,\n",
      "       4.0948441e-07, 9.9999350e-01, 5.0120306e-08, 4.5108157e-09,\n",
      "       2.8594538e-06, 5.1123283e-09, 1.8147182e-08, 4.2394527e-07,\n",
      "       4.1813328e-10, 3.4067220e-08, 2.5568815e-08, 5.0834785e-08,\n",
      "       7.0828952e-09, 1.0894191e-08, 1.8167208e-07, 2.0947508e-09],\n",
      "      dtype=float32), array([4.57873853e-07, 9.41941138e-08, 7.37133865e-09, 3.14093072e-08,\n",
      "       6.20275165e-09, 3.96324467e-08, 5.53958301e-08, 6.40434692e-08,\n",
      "       1.88016770e-07, 9.99992609e-01, 3.46844018e-07, 1.69570924e-07,\n",
      "       6.76220111e-07, 1.97184207e-07, 3.96600797e-07, 3.22683445e-06,\n",
      "       4.76976147e-08, 1.03821344e-06, 1.13323914e-07, 3.52661601e-07,\n",
      "       3.88450907e-08, 2.82463350e-08, 4.68932093e-08, 3.73296594e-09],\n",
      "      dtype=float32), array([9.8718065e-06, 2.2876782e-05, 9.5745290e-06, 1.0202098e-05,\n",
      "       5.8747760e-06, 2.8461393e-06, 7.5536074e-05, 3.4628640e-05,\n",
      "       9.0643793e-04, 7.4680982e-04, 9.8613580e-04, 1.1963582e-04,\n",
      "       6.1262253e-05, 9.7288334e-01, 3.3660317e-04, 2.5912383e-05,\n",
      "       1.2098252e-03, 2.2266062e-02, 1.5036306e-05, 1.4568424e-05,\n",
      "       1.7111810e-04, 4.5546654e-05, 9.1271650e-06, 3.1302818e-05],\n",
      "      dtype=float32), array([5.00795868e-05, 1.33093645e-05, 1.59543488e-04, 8.18874832e-06,\n",
      "       3.93289929e-06, 6.94965565e-05, 2.88221891e-05, 2.41252565e-06,\n",
      "       3.43930296e-05, 4.44572725e-05, 2.47446969e-05, 1.32334881e-05,\n",
      "       2.35270018e-05, 9.47833396e-05, 6.29102942e-05, 1.97455651e-04,\n",
      "       1.26993822e-04, 2.02074880e-05, 1.61312113e-03, 3.84953659e-04,\n",
      "       1.39168873e-02, 9.82457697e-01, 3.08454328e-05, 6.18001563e-04],\n",
      "      dtype=float32), array([6.6050759e-04, 8.0156838e-07, 1.0895030e-04, 1.9516412e-04,\n",
      "       2.2832479e-05, 1.0939228e-05, 2.3135384e-05, 2.0759430e-06,\n",
      "       3.6575052e-06, 2.9937812e-06, 2.8394570e-04, 9.8779847e-06,\n",
      "       6.0247717e-06, 1.9880003e-04, 6.2906242e-05, 1.2887309e-04,\n",
      "       1.0016413e-04, 9.1231945e-05, 9.9481821e-01, 2.0045554e-03,\n",
      "       6.6375948e-04, 4.8156283e-04, 3.2406086e-05, 8.6502201e-05],\n",
      "      dtype=float32), array([1.79191022e-06, 7.70360714e-07, 3.87955606e-06, 3.81571917e-05,\n",
      "       1.46524762e-04, 1.40590498e-06, 2.82039809e-06, 5.17412309e-06,\n",
      "       4.19733851e-06, 1.12391126e-05, 1.27835126e-04, 4.03103586e-05,\n",
      "       3.19042883e-05, 3.43156426e-04, 2.30172882e-03, 7.10466247e-06,\n",
      "       4.89450576e-05, 3.15728365e-04, 1.04977895e-04, 1.92676343e-05,\n",
      "       9.96282041e-01, 9.89225882e-05, 1.52897919e-05, 4.68768121e-05],\n",
      "      dtype=float32), array([8.7725277e-07, 4.1305598e-06, 5.8941087e-06, 8.6491821e-07,\n",
      "       1.1903633e-05, 1.8139730e-05, 5.6236508e-06, 9.9749273e-01,\n",
      "       1.0549867e-03, 3.9073242e-05, 7.6079590e-07, 1.7948460e-06,\n",
      "       1.7996834e-05, 9.3633891e-04, 5.4350727e-07, 3.6859128e-04,\n",
      "       2.9788953e-06, 1.0324867e-05, 5.6845113e-07, 6.5657923e-07,\n",
      "       1.9940169e-06, 1.2756678e-06, 7.3583828e-06, 1.4606723e-05],\n",
      "      dtype=float32), array([4.6342559e-04, 2.2376055e-04, 4.6482943e-05, 1.3633280e-04,\n",
      "       1.0404881e-05, 7.6418644e-04, 9.1679038e-05, 1.2350084e-03,\n",
      "       9.3535149e-05, 9.9533165e-01, 1.7344153e-05, 4.6654914e-05,\n",
      "       7.2743867e-05, 1.8099738e-05, 1.2749563e-04, 3.5427121e-04,\n",
      "       5.1557345e-07, 2.2065788e-05, 1.0989386e-05, 4.9618302e-06,\n",
      "       3.0638612e-06, 1.3497689e-05, 9.1076893e-04, 1.0190695e-06],\n",
      "      dtype=float32), array([1.02984204e-05, 2.56330310e-03, 1.00525995e-05, 4.95058084e-05,\n",
      "       1.52952038e-03, 1.30835630e-04, 2.08560918e-02, 9.08887923e-01,\n",
      "       3.47963371e-03, 3.12555656e-02, 3.38421305e-05, 5.86073693e-05,\n",
      "       1.95682235e-02, 8.40627588e-03, 2.57832107e-05, 7.84126823e-05,\n",
      "       2.16630078e-03, 1.57468327e-04, 7.42256088e-06, 3.72263494e-05,\n",
      "       1.69081559e-05, 4.51048327e-05, 6.73176110e-05, 5.58481610e-04],\n",
      "      dtype=float32), array([4.2456127e-06, 3.8161161e-05, 2.8934758e-06, 3.9689598e-06,\n",
      "       7.5845555e-06, 7.7343939e-06, 7.9730889e-05, 1.7800850e-03,\n",
      "       2.5509819e-03, 7.0827217e-03, 1.5168341e-05, 1.6701555e-05,\n",
      "       9.8475718e-01, 1.1783996e-04, 2.9715064e-05, 6.8705995e-04,\n",
      "       1.6502754e-04, 1.4609075e-05, 3.8947278e-06, 1.1593729e-05,\n",
      "       9.4853727e-05, 1.3853799e-03, 3.5155026e-04, 7.9143915e-04],\n",
      "      dtype=float32), array([6.63246027e-08, 3.72851652e-08, 6.04398025e-08, 5.10374765e-09,\n",
      "       1.87122211e-07, 2.31531146e-07, 1.78742016e-06, 1.58733300e-07,\n",
      "       8.31613178e-09, 1.09599364e-06, 2.11512898e-07, 1.64583938e-08,\n",
      "       2.29744114e-06, 1.23088248e-05, 3.01846285e-07, 4.80855874e-07,\n",
      "       3.04418961e-07, 9.99971747e-01, 2.92015920e-06, 5.61411935e-06,\n",
      "       1.09040165e-07, 1.24372272e-08, 3.35197790e-08, 1.44706263e-07],\n",
      "      dtype=float32), array([1.45725403e-06, 4.64548111e-06, 1.05993831e-05, 6.52402377e-06,\n",
      "       9.99848604e-01, 3.08476658e-08, 2.45319029e-06, 4.86264526e-06,\n",
      "       2.61373407e-05, 1.70548887e-07, 1.01688656e-07, 1.97005716e-06,\n",
      "       3.01567961e-05, 1.18681626e-07, 2.08381171e-05, 1.22426613e-07,\n",
      "       1.54380973e-06, 2.43650975e-05, 6.47651461e-08, 3.33867369e-08,\n",
      "       4.63255994e-08, 1.55222821e-07, 1.47599367e-05, 2.51973375e-07],\n",
      "      dtype=float32), array([5.3673182e-05, 9.9651295e-01, 9.9605159e-06, 8.0499467e-06,\n",
      "       2.5339014e-05, 1.2860269e-05, 8.0125574e-06, 7.4388483e-04,\n",
      "       3.8906292e-04, 6.9585774e-05, 6.0837890e-04, 1.5051455e-05,\n",
      "       4.3731666e-04, 1.7677628e-05, 5.4046177e-07, 8.4729476e-07,\n",
      "       1.0321557e-03, 2.1143424e-05, 1.3149364e-07, 3.8051246e-07,\n",
      "       5.7168234e-07, 5.6619609e-07, 3.1068681e-05, 8.4999556e-07],\n",
      "      dtype=float32), array([9.9999398e-01, 1.8821468e-06, 2.3185547e-07, 6.8660462e-08,\n",
      "       6.3985379e-07, 7.7327462e-07, 8.2352875e-07, 8.6884675e-08,\n",
      "       8.0204741e-09, 1.1426406e-07, 9.9470277e-08, 4.2685706e-08,\n",
      "       1.5387558e-07, 2.0711783e-08, 9.5180063e-08, 5.8642564e-07,\n",
      "       5.9432057e-08, 9.1059089e-09, 2.2601745e-09, 1.6220910e-09,\n",
      "       8.1375506e-10, 2.7127796e-09, 3.4669662e-07, 2.8015845e-09],\n",
      "      dtype=float32), array([4.7979830e-07, 2.6489192e-07, 2.9678350e-07, 9.9971867e-01,\n",
      "       1.8433158e-04, 5.9424394e-07, 5.9777409e-07, 2.2199762e-07,\n",
      "       5.2741775e-06, 1.3215585e-05, 1.2553047e-05, 3.9923740e-05,\n",
      "       1.1925218e-06, 5.7485800e-06, 3.0695967e-06, 2.1169430e-07,\n",
      "       9.9082865e-07, 6.9770886e-07, 7.5657927e-06, 7.2261406e-07,\n",
      "       9.7103919e-07, 6.4539790e-07, 8.5813144e-07, 9.8447356e-07],\n",
      "      dtype=float32), array([1.1913108e-07, 1.2920184e-07, 1.0390753e-07, 2.0517944e-06,\n",
      "       1.1035766e-04, 2.5595949e-07, 2.0962077e-06, 3.8850970e-07,\n",
      "       5.6374006e-06, 3.7481564e-07, 1.4362662e-04, 9.9971616e-01,\n",
      "       4.2083208e-08, 5.4319861e-07, 7.5933931e-06, 3.3735009e-07,\n",
      "       3.7811278e-06, 4.3715795e-06, 9.0728030e-08, 2.7064269e-07,\n",
      "       7.1681075e-07, 5.9531101e-07, 3.7403996e-07, 6.8754481e-08],\n",
      "      dtype=float32), array([4.45349059e-07, 5.43824763e-06, 5.89278397e-06, 1.26758073e-06,\n",
      "       1.32183368e-06, 9.99982536e-01, 1.23904243e-07, 1.55125122e-07,\n",
      "       1.62735212e-08, 9.04541722e-08, 1.27269658e-07, 5.68429698e-07,\n",
      "       6.83811550e-07, 1.07905347e-08, 1.14991366e-07, 1.40771789e-07,\n",
      "       7.72554216e-08, 1.22579662e-08, 1.75865154e-07, 8.14700751e-09,\n",
      "       5.86956839e-09, 2.07687894e-08, 7.14904445e-07, 1.58586786e-07],\n",
      "      dtype=float32), array([3.0031031e-06, 6.3930077e-07, 5.3953231e-06, 5.9740529e-07,\n",
      "       1.1760894e-05, 8.5680676e-07, 3.2328226e-06, 8.1342339e-05,\n",
      "       1.9114769e-07, 4.8423622e-06, 2.5864285e-06, 3.3358776e-07,\n",
      "       1.9530589e-06, 4.3619289e-05, 7.5573706e-07, 1.3349537e-06,\n",
      "       5.1432257e-06, 9.6415985e-01, 1.0300017e-06, 1.2056973e-06,\n",
      "       4.3333002e-05, 5.0091248e-06, 2.4769943e-06, 3.5619557e-02],\n",
      "      dtype=float32), array([1.0757685e-06, 1.0066802e-07, 1.3151832e-08, 1.3389476e-08,\n",
      "       3.8408593e-06, 9.6874153e-08, 3.4992325e-05, 9.9967486e-01,\n",
      "       1.4549970e-07, 7.2523949e-07, 6.7981311e-08, 5.4418371e-07,\n",
      "       1.8189987e-04, 9.7269054e-05, 4.9438267e-08, 5.7123032e-07,\n",
      "       6.2453388e-08, 3.5669751e-07, 4.8451576e-09, 4.4970779e-08,\n",
      "       2.4070832e-07, 2.1691994e-07, 9.1317730e-07, 2.0654018e-06],\n",
      "      dtype=float32), array([1.28025295e-06, 5.70740575e-08, 3.87697725e-07, 5.80598737e-07,\n",
      "       6.46070703e-07, 1.78598134e-06, 2.80611715e-07, 1.13624985e-07,\n",
      "       4.39792132e-08, 2.37234667e-06, 3.20172148e-06, 1.71647036e-06,\n",
      "       7.48709454e-07, 2.07298726e-07, 3.23310596e-05, 3.62349977e-03,\n",
      "       1.64662140e-06, 3.25288311e-05, 9.96166348e-01, 3.05743233e-05,\n",
      "       2.62966460e-05, 6.09160961e-05, 9.34933450e-06, 3.09552956e-06],\n",
      "      dtype=float32), array([4.7939825e-06, 2.8110417e-05, 1.5786003e-05, 8.7644621e-06,\n",
      "       5.7006098e-05, 1.6054657e-06, 7.6241872e-06, 5.8040794e-05,\n",
      "       2.3204644e-04, 6.8906347e-06, 4.7612019e-05, 9.1418160e-06,\n",
      "       1.5588806e-05, 1.8038166e-06, 4.4252803e-05, 1.6048602e-06,\n",
      "       7.2076091e-07, 5.9975486e-07, 1.2576239e-06, 2.6309558e-06,\n",
      "       1.4104022e-06, 3.1957059e-06, 9.9944919e-01, 4.7247514e-07],\n",
      "      dtype=float32), array([4.86561294e-05, 2.19038066e-05, 6.66814507e-04, 2.87922139e-05,\n",
      "       5.10184036e-04, 1.13446236e-04, 1.17412492e-04, 3.30283037e-05,\n",
      "       3.39414000e-05, 2.27805704e-05, 2.44003841e-05, 1.04169594e-03,\n",
      "       3.38247581e-03, 8.77246475e-06, 2.15705042e-03, 5.02582880e-05,\n",
      "       3.09558345e-05, 7.49375758e-05, 6.73917530e-05, 5.20860485e-05,\n",
      "       4.24005484e-05, 1.38460455e-04, 9.91261005e-01, 7.12938709e-05],\n",
      "      dtype=float32), array([5.21360981e-08, 4.30802025e-08, 1.04429795e-07, 9.99987543e-01,\n",
      "       9.55063388e-06, 1.33985822e-07, 3.75264939e-08, 3.02139000e-07,\n",
      "       2.40241548e-07, 7.63159136e-09, 2.70367710e-08, 1.37436146e-07,\n",
      "       6.46307740e-07, 5.32860724e-08, 6.15897093e-08, 2.30275110e-09,\n",
      "       1.06345892e-08, 4.33665903e-09, 8.63001901e-08, 4.56781173e-08,\n",
      "       4.81301266e-09, 1.89324467e-09, 7.56006784e-07, 9.57134176e-08],\n",
      "      dtype=float32), array([5.3503227e-06, 5.0300809e-05, 8.4463039e-08, 1.4591792e-06,\n",
      "       1.1246497e-04, 7.3882475e-06, 5.0724335e-05, 9.9957609e-01,\n",
      "       7.7048242e-07, 2.6986490e-06, 1.1265529e-05, 3.0917043e-05,\n",
      "       1.8261118e-05, 1.0737355e-04, 9.4161305e-07, 1.5897238e-06,\n",
      "       6.3409411e-06, 8.1783182e-06, 3.4359482e-07, 2.3936806e-07,\n",
      "       1.2279345e-06, 5.8133020e-07, 1.7037300e-06, 3.7153800e-06],\n",
      "      dtype=float32), array([2.2348533e-07, 1.7281776e-07, 2.4437265e-06, 3.5911793e-08,\n",
      "       5.0753721e-07, 1.3813501e-07, 4.2933756e-05, 2.0325894e-07,\n",
      "       1.8235866e-06, 1.9424982e-05, 2.9155021e-04, 1.8499964e-05,\n",
      "       3.5654435e-07, 3.2759053e-06, 1.4347751e-06, 7.6878736e-05,\n",
      "       2.5619001e-05, 9.9949217e-01, 3.5048813e-06, 8.5682541e-06,\n",
      "       1.8342505e-06, 3.8921248e-06, 6.6647431e-07, 3.8589501e-06],\n",
      "      dtype=float32), array([1.8086995e-08, 6.8918511e-09, 9.1758025e-08, 7.1943002e-10,\n",
      "       5.2052545e-08, 3.2582221e-08, 2.9328307e-06, 4.7278867e-08,\n",
      "       1.1368820e-08, 1.9046373e-06, 1.2477151e-06, 3.8104531e-07,\n",
      "       4.4210175e-08, 5.2557539e-07, 5.3578898e-08, 7.2515030e-07,\n",
      "       1.6295864e-07, 9.9999082e-01, 5.8759774e-08, 4.6187782e-08,\n",
      "       4.9441138e-07, 2.5586959e-07, 1.1095643e-08, 6.5578789e-08],\n",
      "      dtype=float32), array([3.7528213e-07, 9.3865629e-07, 3.1028330e-07, 5.9416743e-07,\n",
      "       3.2954704e-05, 1.0541231e-07, 6.9624474e-07, 5.3180736e-07,\n",
      "       3.4185089e-07, 6.2270703e-07, 1.9123291e-07, 8.7004466e-08,\n",
      "       5.4837324e-07, 5.1136706e-08, 7.9318414e-07, 8.8376289e-08,\n",
      "       9.2836387e-09, 9.8224007e-08, 6.2724602e-08, 2.1387038e-07,\n",
      "       8.5855119e-09, 2.6445207e-08, 9.9996048e-01, 9.4935739e-09],\n",
      "      dtype=float32), array([3.5384723e-08, 4.6302366e-09, 3.5176862e-07, 1.0831422e-07,\n",
      "       3.5253078e-07, 3.4996557e-08, 5.8873877e-07, 2.9199501e-08,\n",
      "       1.5810380e-09, 3.0116993e-08, 1.5592036e-08, 1.5520431e-08,\n",
      "       3.4344826e-08, 4.6902979e-09, 3.1471332e-06, 3.2409403e-07,\n",
      "       3.6308953e-10, 8.8951984e-09, 8.1236072e-07, 2.9131096e-08,\n",
      "       1.3874183e-08, 1.9566469e-08, 9.9999404e-01, 8.0968396e-09],\n",
      "      dtype=float32), array([2.1254560e-05, 3.4496765e-07, 8.7317055e-08, 5.3100980e-08,\n",
      "       8.2987617e-09, 3.5037442e-06, 7.2236350e-07, 6.2845220e-07,\n",
      "       1.3389297e-06, 9.9600395e-05, 1.7442393e-06, 7.5854224e-08,\n",
      "       1.7415774e-06, 1.4539274e-06, 7.9248457e-07, 9.9960244e-01,\n",
      "       5.2939379e-07, 1.5214121e-04, 4.1071835e-05, 6.8891768e-06,\n",
      "       1.0726109e-06, 6.1100473e-05, 4.5223186e-07, 9.2264133e-07],\n",
      "      dtype=float32), array([5.6002823e-06, 4.2141110e-05, 7.6453842e-05, 2.4125095e-05,\n",
      "       3.2946363e-04, 2.2817514e-06, 5.2396270e-05, 5.2898555e-05,\n",
      "       4.5262836e-06, 7.6836608e-05, 5.1385428e-05, 1.1609903e-05,\n",
      "       2.8105648e-03, 4.9508537e-05, 6.3924112e-05, 6.9550770e-05,\n",
      "       4.1406558e-04, 5.8097094e-03, 4.4711360e-05, 3.3704793e-05,\n",
      "       7.1893322e-05, 6.8528140e-03, 8.7726155e-05, 9.8296213e-01],\n",
      "      dtype=float32), array([7.82182269e-06, 1.07654203e-04, 3.23976451e-07, 9.02257962e-05,\n",
      "       8.96295205e-06, 1.72005014e-06, 3.42950050e-04, 1.96035180e-04,\n",
      "       1.17763047e-04, 2.29227869e-03, 1.07673266e-04, 1.03977509e-04,\n",
      "       9.92435157e-01, 3.95522919e-03, 4.45841897e-06, 1.89371713e-05,\n",
      "       6.14813398e-05, 5.83891160e-05, 9.83689915e-07, 7.64676315e-06,\n",
      "       4.38381403e-06, 3.25708902e-06, 8.40644316e-06, 6.43629173e-05],\n",
      "      dtype=float32), array([1.4456994e-03, 5.9258711e-04, 5.8998396e-03, 1.7212461e-04,\n",
      "       2.5929434e-03, 4.7502941e-03, 1.3502482e-03, 5.2463496e-04,\n",
      "       1.7927334e-04, 4.0654541e-04, 1.1746819e-03, 6.9560856e-04,\n",
      "       1.5903831e-02, 5.2297040e-04, 2.4683356e-02, 6.3695275e-04,\n",
      "       9.0068293e-01, 2.2242665e-02, 5.2088699e-03, 9.1780239e-05,\n",
      "       4.6591868e-04, 1.8923229e-03, 5.6939246e-04, 7.3146401e-03],\n",
      "      dtype=float32), array([1.9201154e-09, 8.8525951e-09, 1.1971660e-09, 2.5586755e-10,\n",
      "       1.2455155e-08, 1.0809312e-08, 1.3007350e-07, 3.0073185e-08,\n",
      "       1.2359583e-09, 1.1740728e-06, 6.3343876e-08, 4.3611141e-08,\n",
      "       5.0410809e-09, 3.0381990e-08, 2.7657970e-08, 5.2734748e-08,\n",
      "       4.8740439e-08, 9.9999851e-01, 2.6396094e-08, 6.2375753e-09,\n",
      "       1.7666739e-08, 3.0294030e-09, 4.1422528e-09, 1.9059136e-08],\n",
      "      dtype=float32), array([4.7149914e-04, 2.3652962e-04, 7.3992130e-03, 3.3602386e-04,\n",
      "       7.4293021e-05, 2.3739722e-03, 1.4972590e-03, 9.0997797e-05,\n",
      "       7.0702907e-04, 1.5569801e-03, 1.6494212e-03, 5.4177834e-04,\n",
      "       5.4666470e-03, 4.3958742e-03, 1.0709873e-02, 1.2811352e-01,\n",
      "       1.6126325e-03, 5.0645717e-03, 6.1810499e-01, 7.6560564e-02,\n",
      "       2.6738008e-02, 1.0553786e-01, 5.2189053e-04, 2.3856347e-04],\n",
      "      dtype=float32), array([1.7114741e-07, 2.9186845e-08, 5.2284992e-07, 8.0826032e-07,\n",
      "       2.2994793e-06, 5.1556555e-07, 6.3723220e-08, 1.7784474e-07,\n",
      "       1.3490359e-07, 1.6731390e-07, 5.3528703e-07, 5.4408201e-07,\n",
      "       5.9764591e-07, 1.6430317e-06, 3.0257513e-06, 2.7085996e-05,\n",
      "       1.8328335e-06, 6.6846051e-06, 9.9909461e-01, 8.7685403e-05,\n",
      "       7.0666330e-04, 6.0835097e-05, 1.8032714e-06, 1.6895232e-06],\n",
      "      dtype=float32), array([0.00589665, 0.0097609 , 0.00702125, 0.00869298, 0.00172266,\n",
      "       0.00588784, 0.00515717, 0.00182802, 0.00459753, 0.00140176,\n",
      "       0.00404599, 0.00659982, 0.11546154, 0.17741778, 0.13843162,\n",
      "       0.00991082, 0.00491042, 0.00237418, 0.00806445, 0.00570982,\n",
      "       0.3383211 , 0.13396527, 0.00208994, 0.00073048], dtype=float32), array([4.1641673e-07, 9.0166719e-09, 5.7922936e-08, 4.6576780e-08,\n",
      "       7.1147305e-08, 2.5823466e-08, 2.8733443e-06, 4.8675015e-06,\n",
      "       1.5587663e-07, 5.8680149e-07, 1.4606475e-06, 3.9786946e-07,\n",
      "       1.9243450e-07, 9.9995148e-01, 7.4013856e-06, 1.2183447e-07,\n",
      "       1.3473457e-06, 2.1206910e-05, 6.2912136e-07, 1.2517060e-06,\n",
      "       5.1577686e-06, 1.0748756e-07, 3.9321790e-08, 1.8725376e-07],\n",
      "      dtype=float32), array([2.5572012e-05, 4.1974677e-06, 9.9981248e-01, 1.7591309e-07,\n",
      "       1.2831575e-06, 1.0379637e-04, 3.9436190e-06, 2.0148298e-06,\n",
      "       8.5449466e-07, 2.2851127e-06, 1.4681143e-07, 3.6388201e-07,\n",
      "       4.7412306e-07, 2.0404599e-07, 2.5854661e-07, 1.2985994e-07,\n",
      "       4.9204449e-08, 3.9129336e-06, 4.1823697e-08, 8.5138126e-08,\n",
      "       2.2559684e-07, 3.7499044e-07, 3.6546408e-05, 7.4606919e-07],\n",
      "      dtype=float32), array([3.6719669e-06, 1.0384035e-04, 8.8304068e-07, 9.9967414e-01,\n",
      "       1.8570956e-04, 3.1621842e-06, 2.9893167e-07, 1.2352305e-05,\n",
      "       5.0684903e-06, 7.2292448e-07, 2.8024094e-06, 4.0415139e-06,\n",
      "       4.5391022e-07, 1.5857818e-06, 3.7163570e-08, 2.8248675e-09,\n",
      "       3.5768753e-08, 1.9777419e-08, 5.9507904e-08, 8.5817602e-09,\n",
      "       1.0399236e-08, 1.1493941e-08, 1.1917635e-06, 6.7429433e-08],\n",
      "      dtype=float32)], l_labels: ['16', '22', '22', '19', '18', '2', '9', '4', '20', '9', '9', '1', '21', '21', '11', '7', '20', '5', '10', '21', '10', '1', '4', '11', '2', '10', '10', '14', '22', '19', '21', '8', '10', '8', '13', '18', '5', '2', '1', '4', '12', '6', '18', '8', '19', 'x', 'x', '4', '8', '18', '18', 'x', 'x', '16', 'y', '13', '17', '18', '19', '19', '13', '14', '3', '4']\n"
     ]
    }
   ],
   "source": [
    "print(f'l_pictures: {l_pictures}, l_outputs: {l_outputs}, l_labels: {l_labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l_pictures: 64, l_outputs: 64, l_labels: 64\n"
     ]
    }
   ],
   "source": [
    "print(f'l_pictures: {len(l_pictures)}, l_outputs: {len(l_outputs)}, l_labels: {len(l_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.984375"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res = pd.DataFrame({'l_pictures': l_pictures, 'l_outputs': l_outputs, 'l_labels': l_labels})\n",
    "index_to_class = pd.read_csv('../data/index_to_class.csv')\n",
    "class_to_index = index_to_class.set_index('class')\n",
    "class_to_index.columns=['idx']\n",
    "df_res['pred'] = df_res['l_outputs'].apply(lambda x: idx2class(np.argmax(x)))\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "df_res\n",
    "len(df_res[df_res['pred']==df_res['l_labels']])/len(df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res['max'] = df_res['l_outputs'].apply(lambda x: x[np.argmax(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l_pictures</th>\n",
       "      <th>l_outputs</th>\n",
       "      <th>l_labels</th>\n",
       "      <th>pred</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>MA160814197500059.034-K_13_0_.png</td>\n",
       "      <td>[0.0058966507, 0.009760899, 0.007021254, 0.008...</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>0.338321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           l_pictures  \\\n",
       "60  MA160814197500059.034-K_13_0_.png   \n",
       "\n",
       "                                            l_outputs l_labels pred       max  \n",
       "60  [0.0058966507, 0.009760899, 0.007021254, 0.008...       13   21  0.338321  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res[df_res['l_labels'] != df_res['pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l_pictures</th>\n",
       "      <th>l_outputs</th>\n",
       "      <th>l_labels</th>\n",
       "      <th>pred</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>MA160814197500059.034-K_13_0_.png</td>\n",
       "      <td>[0.0058966507, 0.009760899, 0.007021254, 0.008...</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>0.338321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           l_pictures  \\\n",
       "60  MA160814197500059.034-K_13_0_.png   \n",
       "\n",
       "                                            l_outputs l_labels pred       max  \n",
       "60  [0.0058966507, 0.009760899, 0.007021254, 0.008...       13   21  0.338321  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res[df_res['max'] < 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.7513102e-05, 7.7717363e-05, 1.1627050e-04, 1.2670270e-04,\n",
       "       1.3202455e-04, 1.5106768e-04, 1.8130631e-04, 2.1694809e-04,\n",
       "       2.2828230e-04, 2.4213789e-04, 2.5248967e-04, 2.5438593e-04,\n",
       "       3.2854051e-04, 4.3526888e-04, 4.4371519e-04, 4.8788716e-04,\n",
       "       4.9940177e-04, 1.3275477e-03, 4.3828557e-03, 4.4687656e-03,\n",
       "       6.1028064e-03, 3.4685001e-02, 4.0953279e-02, 9.0387809e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_x=df_res['l_outputs'][1]\n",
    "l_x.sort()\n",
    "l_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res[df_res['l_pictures'] == 'MA160865191500021.009-K_10_1_.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res[df_res['l_pictures'] == 'MA160865191500021.009-K_10_1_.png']['l_outputs'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel1=[1,2,3]\n",
    "mel2=[[4,5]]\n",
    "mel1.append(np_output_single)\n",
    "len(mel1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x=df_res[df_res['l_pictures'] == 'MA160865191500021.009-K_10_1_.png']['l_outputs'][0]\n",
    "x=df_res[df_res['l_pictures'] == 'MA160865191500021.009-K_10_1_.png']['l_outputs'][0]\n",
    "q75, q25 = np.percentile(x, [75 ,25])\n",
    "iqr = q75 - q25\n",
    "iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df_res['l_outputs'][0]\n",
    "q75, q25 = np.percentile(x, [75 ,25])\n",
    "iqr = q75 - q25\n",
    "iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iqr = np.subtract(*np.percentile(x, [75, 25]))\n",
    "iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res['iqr'] = df_res['l_outputs'].apply(lambda x: np.subtract(*np.percentile(x, [75, 25])))\n",
    "\n",
    "def unc_top2(x):\n",
    "    x.sort()\n",
    "    unc=(x[-1] - x[-2])/x[-1]*100\n",
    "    return unc    \n",
    "    \n",
    "df_res['unc_top2'] = df_res['l_outputs'].apply(unc_top2)\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res['unc_top2'] = df_res['l_outputs'].apply(unc_top2)\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_res[df_res['l_labels'] == df_res['pred']]\n",
    "df_res[(df_res['unc_top2'] > 70) & (df_res['l_labels'] != df_res['pred'])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx=df_res['l_outputs'][0]\n",
    "xx.sort()\n",
    "xx[-1] - xx[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res['iqr'] = df_res['l_outputs'].apply(lambda x: np.subtract(*np.percentile(x, [75, 25])))\n",
    "# df_res['top2'] = df_res['l_outputs'].apply(lambda x: np.subtract(*np.percentile(x, [75, 25])))\n",
    "# df_res['iqr'] = df_res['l_outputs'].apply(lambda x: np.subtract(*np.percentile(x, [75, 25])))\n",
    "#df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = data_transforms_augmentation['val3']\n",
    "# input_s = transform(input_s)\n",
    "multiple_copies = False\n",
    "if multiple_copies:\n",
    "    input_s = inputs[9,6,...]\n",
    "    input_s = transform(input_s)\n",
    "else:\n",
    "    input_s = inputs[9,...]\n",
    "input_s = input_s.permute(1, 2, 0)\n",
    "input_s = input_s.to('cpu')\n",
    "input_s = input_s.detach().numpy()\n",
    "# input_s.shape\n",
    "plt.imshow(input_s, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs2 = model_test(image2.reshape([1, 3, 224, 224]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs2+outputs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs2 = outputs2.to('cpu')\n",
    "outputs2 = outputs2.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros([1, 24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image2.reshape([1, 3, 224, 224])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = data_transforms_augmentation['val3']\n",
    "image2 = transform(image)\n",
    "image3 = image2.permute(1, 2, 0)\n",
    "#image2 = image2.permute(1, 2, 0)\n",
    "#image2 = image2.to('cpu')\n",
    "#image2 = image2.detach().numpy()\n",
    "# input_s.shape\n",
    "plt.imshow(image3, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res['l_outputs'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(input_s, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx2class(idx):\n",
    "    return index_to_class[index_to_class['index']==idx]['class'][idx]\n",
    "\n",
    "idx2class(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx2class(idx):\n",
    "    return index_to_class[index_to_class['index']==idx]['class'][idx]\n",
    "\n",
    "df_res = pd.DataFrame({'l_pictures': l_pictures, 'l_outputs': l_outputs, 'l_labels': l_labels})\n",
    "index_to_class = pd.read_csv('../data/index_to_class.csv')\n",
    "class_to_index = index_to_class.set_index('class')\n",
    "class_to_index.columns=['idx']\n",
    "df_res['pred'] = df_res['l_outputs'].apply(lambda x: idx2class(np.argmax(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res[df_res['l_pictures'] == 'MA160865191500021.009-K_10_1_.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_res[df_res['pred']==df_res['l_labels']])/len(df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_test = False\n",
    "start_date=datetime.datetime.now()\n",
    "print(start_date)\n",
    "if execute_test:        \n",
    "    #%run test_model --config ../config/config_squeezenet1_0.ini\n",
    "    %run test_model_augmentation --config ../config/config_densenet121_augmentation.ini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN TEST ON PICTURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', -1)\n",
    "# idx=np.argmax(df_result_ensemble.iloc[0]['outputs_mean'])\n",
    "# df_result_ensemble.iloc[0]['outputs_mean'][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tm1.df_result\n",
    "print(f'uncertainty running: {datetime.datetime.now()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN UNCERTAINTY CALCULATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', 500)\n",
    "# saving a DataFrame as csv saves lista (e.g. outputs_mean) as string which leads to conversion problems \n",
    "# while loading. so, it's better to save as a pickle file and load it back.\n",
    "# with open('../results/squeezenet1_0_11.05.2021_02.07.07_df_result_ensemble.pkl', 'rb') as fp:\n",
    "#      df_result_ensemble = pickle.load(fp)\n",
    "\n",
    "# df_result_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuc1 = tuc.test_uncertainty('../config/config_squeezenet1_0.ini')\n",
    "# tuc1 = tuc.test_uncertainty('../config/config_alexnet.ini')\n",
    "# tuc1 = tuc.test_uncertainty('../config/config_resnet18.ini')\n",
    "# use_sample_weights = [0,1,3,5,6]\n",
    "use_sample_weights = [-1]  # if -1 then use all weights in the given ***** result pkl ******\n",
    "tuc1 = tuc.test_uncertainty('../config/config_densenet121.ini', use_sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(len(tuc1.df_result_ensemble.loc[0,'outputs_all'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_class = pd.read_csv('../data/index_to_class.csv')\n",
    "# index_to_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_index = index_to_class.set_index('class')\n",
    "class_to_index.columns=['idx']\n",
    "# class_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Per Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_column = []\n",
    "if use_sample_weights == [-1]:\n",
    "    use_sample_weights = list(range(len(tuc1.df_result_ensemble.loc[0,'outputs_all'])))\n",
    "\n",
    "# accuracy per model\n",
    "for i, sample_model in enumerate(use_sample_weights):\n",
    "    tuc1.df_result_ensemble[f'pred_{sample_model}'] = \\\n",
    "        tuc1.df_result_ensemble.loc[:,'outputs_all'].apply(lambda x: np.argmax(x[i]))\n",
    "    lst_column.append(f'pred_{sample_model}')\n",
    "\n",
    "# accuracy per model\n",
    "n_models = len(use_sample_weights)\n",
    "count_correct = np.zeros(n_models)\n",
    "lst_incorrect = [[] for i in range(n_models)]\n",
    "    \n",
    "for pic in range(len(tuc1.df_result_ensemble)):\n",
    "    true_label = tuc1.df_result_ensemble['label'][pic]\n",
    "    for i, sample_model in enumerate(use_sample_weights):\n",
    "        #tuc1.index_to_class['class'][tuc1.df_result_ensemble[f'pred_{sample_model}'][pic]]\n",
    "        if tuc1.index_to_class['class'][tuc1.df_result_ensemble.loc[pic ,f'pred_{sample_model}']] == true_label:\n",
    "            count_correct[i] += 1\n",
    "        else:\n",
    "            lst_incorrect[i].append(pic)\n",
    "\n",
    "# count_correct/len(tuc1.df_result_ensemble)*100\n",
    "[round(x/len(tuc1.df_result_ensemble)*100,4) for x in count_correct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuc1.df_result_ensemble.iloc[:2, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuc1.df_result_ensemble.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuc1.run()\n",
    "df_results_eval = tuc1.df_uncertainty  # df_final\n",
    "df_final_summary = tuc1.df_final_summary\n",
    "\n",
    "df_results_eval\n",
    "#df_results_eval.loc[:0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuc1.df_result_ensemble.drop(columns=['preds','preds_count', 'preds_rate', 'Incorrect'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuc1.df_result_ensemble['preds'] = \\\n",
    "[row for row in tuc1.df_result_ensemble[lst_column].values]\n",
    "\n",
    "tuc1.df_result_ensemble['preds_count'] = \\\n",
    "tuc1.df_result_ensemble['preds'].apply(lambda x: np.bincount(x))\n",
    "\n",
    "tuc1.df_result_ensemble['preds_rate'] = \\\n",
    "tuc1.df_result_ensemble['preds_count'].apply(lambda x: x[np.argmax(x)]/n_models)\n",
    "\n",
    "l_column = ['picture', 'model', 'label', 'preds','preds_count', 'preds_rate']+lst_column\n",
    "\n",
    "searchfor = list(df_results_eval[df_results_eval['actual_class']!=df_results_eval['best_pred']]['picture'])\n",
    "\n",
    "tuc1.df_result_ensemble['Incorrect']=tuc1.df_result_ensemble['picture'].apply(lambda x: \\\n",
    "                                                1 if any(i in x for i in searchfor) else 0)\n",
    "\n",
    "df_results_eval['Incorrect']=df_results_eval['picture'].apply(lambda x: \\\n",
    "                                                1 if any(i in x for i in searchfor) else 0)\n",
    "\n",
    "#tuc1.df_result_ensemble.iloc[:5, -8:]\n",
    "tuc1.df_result_ensemble.loc[:5, l_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # searchfor = ['MA160814197500042.017-K_9_0_.png', 'MA160814197500041.070-K_4_0_.png']\n",
    "# searchfor = list(df_results_eval[df_results_eval['actual_class']!=df_results_eval['best_pred']]['picture'])\n",
    "# # s[s.str.contains('|'.join(searchfor))]\n",
    "# # tuc1.df_result_ensemble[tuc1.df_result_ensemble['pred_6'].str.contains('|'.join(searchfor))]\n",
    "\n",
    "# tuc1.df_result_ensemble['Incorrect']=tuc1.df_result_ensemble['picture'].apply(lambda x: 1 if any(i in x for i in searchfor) else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuc1.df_result_ensemble.drop(columns=['preds','preds_count','preds_max', 'Incorrect'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuc1.df_result_ensemble.iloc[:2,-11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst_column = []\n",
    "# for i in range(n_models):\n",
    "#     lst_column.append(f'pred_{i}')\n",
    "\n",
    "# lst_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst_column = []\n",
    "# for i in range(n_models):\n",
    "#     lst_column.append(f'pred_{i}')\n",
    "# vertical variance\n",
    "\n",
    "l_th, l_FP, l_TN, l_FN, l_work_count, l_fail_count, l_work_rate, l_fail_rate = [],[],[],[],[],[],[],[] \n",
    "# th_rate = round(1/n_models*5+0.01, 2) # e.g 0.68\n",
    "\n",
    "# l_FP = len(tuc1.df_result_ensemble[(tuc1.df_result_ensemble['Incorrect']==1) & \\\n",
    "#                         (tuc1.df_result_ensemble['preds_rate']>=th_rate)].loc[:, lst_column])\n",
    "\n",
    "# l_TN = len(tuc1.df_result_ensemble[(tuc1.df_result_ensemble['Incorrect']==1) & \\\n",
    "#                         (tuc1.df_result_ensemble['preds_rate']<=th_rate)].loc[:, lst_column])\n",
    "\n",
    "# l_FN = len(tuc1.df_result_ensemble[(tuc1.df_result_ensemble['Incorrect']==0) & \\\n",
    "#                         (tuc1.df_result_ensemble['preds_rate']<=th_rate)].loc[:, lst_column])\n",
    "\n",
    "# work_load = l_FN+l_TN\n",
    "# fail_rate = l_FP\n",
    "\n",
    "# print(f'threshold={th_rate} .. l_FN: {l_FN} .. l_FN: {l_TN} .. l_FN: {l_FP}')\n",
    "# print(f'work_load(%): {round(work_load/len(tuc1.df_result_ensemble)*100, 2)} .. n_work_load: {work_load}')\n",
    "# print(f'fail_rate(%): {round(fail_rate/len(tuc1.df_result_ensemble)*100, 2)} .. fail_rate: {fail_rate}')\n",
    "\n",
    "for i in range(n_models):\n",
    "    th_rate = round(1/n_models*i+0.01, 2)\n",
    "    n_FP = len(tuc1.df_result_ensemble[(tuc1.df_result_ensemble['Incorrect']==1) & \\\n",
    "                        (tuc1.df_result_ensemble['preds_rate']>=th_rate)].loc[:, lst_column])\n",
    "\n",
    "    n_TN = len(tuc1.df_result_ensemble[(tuc1.df_result_ensemble['Incorrect']==1) & \\\n",
    "                            (tuc1.df_result_ensemble['preds_rate']<=th_rate)].loc[:, lst_column])\n",
    "\n",
    "    n_FN = len(tuc1.df_result_ensemble[(tuc1.df_result_ensemble['Incorrect']==0) & \\\n",
    "                            (tuc1.df_result_ensemble['preds_rate']<=th_rate)].loc[:, lst_column])\n",
    "\n",
    "    n_work_count = n_FN + n_TN\n",
    "    n_fail_count = n_FP\n",
    "    \n",
    "    l_th.append(th_rate)\n",
    "    l_FP.append(n_FP)\n",
    "    l_TN.append(n_TN)\n",
    "    l_FN.append(n_FN)\n",
    "    l_work_count.append(n_work_count)\n",
    "    l_fail_count.append(n_fail_count)\n",
    "    l_fail_rate.append(round(n_fail_count/len(tuc1.df_result_ensemble)*100, 2))\n",
    "    l_work_rate.append(round(n_work_count/len(tuc1.df_result_ensemble)*100, 2))\n",
    "    \n",
    "    df_ensemble_res = pd.DataFrame({'th': l_th, 'FP': l_FP, 'TN': l_TN, 'FN': l_FN, 'Work_Load': l_work_count, \n",
    "                      'Fail Rate': l_fail_count, 'Work_Load (%)': l_work_rate, 'Fail Rate (%)': l_fail_rate})\n",
    "\n",
    "df_ensemble_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flexible = df_ensemble_res[(df_ensemble_res['Work_Load (%)']<=5) & (df_ensemble_res['Fail Rate (%)']<=3)] \n",
    "lst_flexible = list(df_flexible['th'])\n",
    "lst_flexible_workload = list(df_flexible['Work_Load (%)'])\n",
    "print(f'{len(lst_flexible)} values from {min(lst_flexible)} to {max(lst_flexible)} having fail rate between 0.5 and 1.0')\n",
    "print(f'workload from {min(lst_flexible_workload)} to {max(lst_flexible_workload)}')\n",
    "\n",
    "print(3.753371-3.622185)\n",
    "print((3.753371-3.622185)/3.622185*100)\n",
    "\n",
    "df_flexible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ensemble_res['Work_Load (%)']<=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter(tuc1.df_result_ensemble.loc[0, 'preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'threshold={th_rate} .. l_FN: {l_FN} .. l_TN: {l_TN} .. l_FP: {l_FP}')\n",
    "# print(f'work_load(%): {round(l_sum/len(tuc1.df_result_ensemble)*100, 2)} .. n_work_load: {work_load}')\n",
    "# print(f'fail_rate(%): {round(fail_rate/len(tuc1.df_result_ensemble)*100, 2)} .. fail_rate: {fail_rate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(142)/len(tuc1.df_result_ensemble)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1135+142)/len(tuc1.df_result_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_count = np.zeros((n_models, n_models))\n",
    "m_ratio = np.zeros((n_models, n_models))\n",
    "m_jaccard = np.zeros((n_models, n_models))  # (A&B)/(A+B)\n",
    "for m1 in range(n_models):    \n",
    "    for m2 in range(m1+1,n_models):\n",
    "        lst_diff=[]\n",
    "        lst_same=[]\n",
    "        for i in lst_incorrect[m1]:\n",
    "            if i in lst_incorrect[m2]:\n",
    "                lst_same.append(i)\n",
    "            else:\n",
    "                lst_diff.append(i)\n",
    "                \n",
    "        m_count[m1,m2]=len(lst_diff)\n",
    "        m_ratio[m1,m2]=round((len(lst_diff)/len(lst_incorrect[m1])),2)\n",
    "        total_incorrect = set(lst_incorrect[m1] + lst_incorrect[m2])\n",
    "        m_jaccard[m1,m2]=round(len(lst_same)/len(total_incorrect),2)   \n",
    "\n",
    "print('Diff_count matrix for incorrect labels between different models')\n",
    "print(m_count)\n",
    "\n",
    "print('\\nDiff_ratio matrix for incorrect labels between different models')\n",
    "print(m_ratio)\n",
    "\n",
    "print('\\nJaccard similarity matrix for incorrect labels between different models')\n",
    "print(m_jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(tuc1.df_result_ensemble)):\n",
    "#     tuc1.df_result_ensemble['outputs_all'][i] = tuc1.df_result_ensemble['outputs_all'][i][lst_max5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "After picking the best-5 accuracy-models, the ensemble accuracy dropped to 96.9827 from 97.092\n",
    "BUT\n",
    "CERTAINTY results getting BETTER\n",
    "'''\n",
    "# lst_acc = count_correct/len(tuc1.df_result_ensemble)*100\n",
    "# lst_acc_sort = lst_acc.copy()\n",
    "# lst_acc_sort.sort()\n",
    "# lst_acc_sort[2]\n",
    "# lst_max5 = [i for i in range(len(lst_acc)) if lst_acc[i]>=lst_acc_sort[2]]\n",
    "# lst_max5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_results_eval[df_results_eval['actual_class']!=df_results_eval['best_pred']]['picture'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = datetime.datetime.now()\n",
    "t_delta = end_date - start_date\n",
    "\n",
    "print(f'ALL done: {end_date} .. total calculation time: {format_timespan(t_delta.seconds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuc1.df_combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_eval.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_test(plt, title='Softmax Score', metric_name='best_score',step_size=0.01, higher_better=True, is_norm=False):\n",
    "    plus_minus = 5\n",
    "    max_val = round(max(df_results_eval[metric_name]), 6)\n",
    "    min_val = round(min(df_results_eval[metric_name]), 6)\n",
    "    mean_val = round(np.mean(df_results_eval[metric_name]), 6)\n",
    "    var_val = round(np.var(df_results_eval[metric_name]), 6)\n",
    "    \n",
    "    norm_name = f'{metric_name}_Norm'\n",
    "    if is_norm and norm_name not in df_results_eval.columns:\n",
    "        df_results_eval[norm_name]=df_results_eval[metric_name].apply(lambda x: (x-min_score)/\n",
    "                                                                      (max_score-min_score)*100)\n",
    "    \n",
    "    print(f'max: {max_val} .. min: {min_val} .. mean: {mean_val} .. var: {var_val}')\n",
    "    \n",
    "    x=[];\n",
    "    TP_temp, FP_temp, TN_temp, FN_temp = 0, 0, 0, 0\n",
    "    TP, FP, TN, FN, TPR, TNR, FPR, FDR, NPV = [], [], [], [], [], [], [], [], []\n",
    "    fail_rate_temp, work_load_temp, fail_rate, work_load = 0, 0, [], []\n",
    "    #for val in tqdm(np.arange(min_val+0.0001, max_val + step_size, step_size)):\n",
    "    for val in tqdm(np.arange(0, max_val + 2*step_size, step_size)):\n",
    "        \n",
    "        # All Correct predictions\n",
    "        len_Correct = len(df_results_eval[df_results_eval['actual_class'] == df_results_eval['best_pred']])\n",
    "        # All INcorrect predictions\n",
    "        len_Incorrect = len(df_results_eval[df_results_eval['actual_class'] != df_results_eval['best_pred']])\n",
    "\n",
    "        if higher_better:\n",
    "            TP_temp =len(df_results_eval[(df_results_eval['actual_class'] == df_results_eval['best_pred']) &\n",
    "                                         (df_results_eval[metric_name] >= val)])                            \n",
    "            FP_temp = len(df_results_eval[(df_results_eval['actual_class'] != df_results_eval['best_pred']) &\n",
    "                                         (df_results_eval[metric_name] >= val)])\n",
    "            TN_temp = len(df_results_eval[(df_results_eval['actual_class'] != df_results_eval['best_pred']) &\n",
    "                                         (df_results_eval[metric_name] < val)])\n",
    "            FN_temp = len(df_results_eval[(df_results_eval['actual_class'] == df_results_eval['best_pred']) &\n",
    "                                         (df_results_eval[metric_name] < val)])          \n",
    "            #print('How many percent of the incorrect images we can miss to detect? = FAILURE RATE')\n",
    "#             fail_rate_temp = len(df_results_eval[(df_results_eval['Incorrect']==1) & \\\n",
    "#                     (df_results_eval[metric_name]>=val)])/len(df_results_eval)*100\n",
    "#             fail_rate.append(fail_rate_temp)\n",
    "            #print('How many percent of the images should be double-checked by the laborants? = WORK LOAD')\n",
    "#             work_load_temp = len(df_results_eval[(df_results_eval['Incorrect']==0) & \\\n",
    "#                     (df_results_eval[metric_name]<val)])/len(df_results_eval)*100\n",
    "            #work_load_temp = len(df_results_eval[df_results_eval[metric_name]<val])/len(df_results_eval)*100\n",
    "            \n",
    "#             len(tuc1.df_result_ensemble[(tuc1.df_result_ensemble['Incorrect']==1) & \\\n",
    "#                         (tuc1.df_result_ensemble['preds_max']>=0.78)].iloc[:,-11:])\n",
    "\n",
    "#             len(tuc1.df_result_ensemble[(tuc1.df_result_ensemble['Incorrect']==0) & \\\n",
    "#                                     (tuc1.df_result_ensemble['preds_max']<=0.78)].iloc[:,-11:])\n",
    "        else:\n",
    "            TP_temp =len(df_results_eval[(df_results_eval['actual_class'] == df_results_eval['best_pred']) &\n",
    "                                         (df_results_eval[metric_name] < val)])                            \n",
    "            FP_temp = len(df_results_eval[(df_results_eval['actual_class'] != df_results_eval['best_pred']) &\n",
    "                                         (df_results_eval[metric_name] < val)])\n",
    "            TN_temp = len(df_results_eval[(df_results_eval['actual_class'] != df_results_eval['best_pred']) &\n",
    "                                         (df_results_eval[metric_name] >= val)])\n",
    "            FN_temp = len(df_results_eval[(df_results_eval['actual_class'] == df_results_eval['best_pred']) &\n",
    "                                         (df_results_eval[metric_name] >= val)])\n",
    "            #print('How many percent of the incorrect images we can miss to detect? = FAILURE RATE'=FP)\n",
    "#             fail_rate_temp = len(df_results_eval[(df_results_eval['Incorrect']==1) & \\\n",
    "#                     (df_results_eval[metric_name]<val)])/len(df_results_eval)*100\n",
    "#             fail_rate.append(fail_rate_temp)\n",
    "            #print('How many percent of the images should be double-checked by the laborants? = WORK LOAD')\n",
    "#             work_load_temp = len(df_results_eval[(df_results_eval['Incorrect']==0) & \\\n",
    "#                     (df_results_eval[metric_name]>=val)])/len(df_results_eval)*100\n",
    "#             work_load_temp = len(df_results_eval[df_results_eval[metric_name]>=val])/len(df_results_eval)*100\n",
    "#             work_load.append(work_load_temp)\n",
    "\n",
    "        TP.append(TP_temp); FP.append(FP_temp); FN.append(FN_temp); TN.append(TN_temp)\n",
    "        fail_rate.append(FP_temp/len(df_results_eval)*100)\n",
    "        work_load_temp = (TN_temp + FN_temp)/len(df_results_eval)*100\n",
    "        work_load.append(work_load_temp)\n",
    "\n",
    "        TPR_temp = 0 if (TP_temp+FN_temp)==0 else TP_temp/(TP_temp+FN_temp)\n",
    "        TNR_temp = 0 if (TN_temp+FP_temp)==0 else TN_temp/(TN_temp+FP_temp)\n",
    "        FPR_temp = 0 if (FP_temp+TN_temp)==0 else FP_temp/(FP_temp+TN_temp)\n",
    "        # FDR (False Discovery Rate) = FP/(FP+TP)  ... FDR = 1 - precision=1-PPV\n",
    "        FDR_temp = 0 if (FP_temp+TP_temp)==0 else FP_temp/(FP_temp+TP_temp)\n",
    "        # NPV (Negative Predictive Value) = TN/(TN+FN)\n",
    "        NPV_temp = 0 if (TN_temp+FN_temp)==0 else TN_temp/(TN_temp+FN_temp)\n",
    "\n",
    "        # https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
    "        x.append(val)\n",
    "        TPR.append(round(TPR_temp,4))  # TP/(TP+FN) = True Positive Rate (sensitivity, recall)\n",
    "        TNR.append(round(TNR_temp,4))  # TN/(TN+FP) = True Negative Rate (pecificity, selectivity)\n",
    "        FPR.append(round(FPR_temp,4))  # FP/(FP+TN) = False Positive Rate (fall-out)\n",
    "        FDR.append(round(FDR_temp,4))  # FP/(FP+TP) = False Discovery Rate \n",
    "        NPV.append(round(NPV_temp,4))  # TN/(TN+FN) = Negative Predictive Value \n",
    "                \n",
    "    df_Res = pd.DataFrame({'val': x, 'TP': TP, 'FP': FP, 'TN': TN, 'FN': FN, 'fail_rate': fail_rate,\n",
    "                          'work_load': work_load})\n",
    "    df_Res['sum'] = df_Res['TN'] + df_Res['FN']\n",
    "    df_Res['diff'] = df_Res['work_load'] - df_Res['fail_rate']\n",
    "    \n",
    "    #arr_diff=np.array(TNR)-np.array(FPR)\n",
    "    # What is the threshold to capture the min. number of False Negative decisions\n",
    "    #arr_diff=np.array(NPV)-np.array(FDR)\n",
    "    arr_diff=np.array(work_load)-np.array(fail_rate)\n",
    "    # What is the threshold to capture the min. number of False Positive decisions\n",
    "#     arr_diff=np.array(FDR)-np.array(NPV)\n",
    "\n",
    "    # find the threshold giving the max diff between NPV (correct-NEGATIVE predictions) \n",
    "    #                                            and FDR (incorrect-POSITIVE predictions)\n",
    "    argmax = np.argmin(np.array(df_Res['diff']**2))\n",
    "    print(f'argmax:{argmax}')\n",
    "    best_threshold = round(x[argmax], 2)\n",
    "\n",
    "    lst_threshold = x[argmax-plus_minus:argmax+plus_minus]\n",
    "#     FDR_th = FDR[argmax-plus_minus:argmax+plus_minus]\n",
    "#     NPV_th = NPV[argmax-plus_minus:argmax+plus_minus]\n",
    "    lst_fail_rate = fail_rate[argmax-plus_minus:argmax+plus_minus]\n",
    "    lst_work_load = work_load[argmax-plus_minus:argmax+plus_minus]\n",
    "    # number of images expected to be incorrectly predicted after uncertainty/certainty filtering\n",
    "    n_total_mistakes = np.array(FP[argmax-plus_minus:argmax+plus_minus]) \\\n",
    "                     + np.array(FN[argmax-plus_minus:argmax+plus_minus])\n",
    "    rate_total_mistakes = np.array(n_total_mistakes)/len(df_results_eval)\n",
    "    rate_FP = np.array(FP[argmax-plus_minus:argmax+plus_minus])/len(df_results_eval)\n",
    "\n",
    "    df_threshold = pd.DataFrame({'threshold': lst_threshold, 'fail_rate': lst_fail_rate, \n",
    "                                 'work_load': lst_work_load, 'total_mistakes': n_total_mistakes, \n",
    "                                 'total_mistakes(%)': rate_total_mistakes, 'FP(%)': rate_FP})\n",
    "\n",
    "    print(f'\\nWhen threshold={best_threshold}:')\n",
    "    print(f'TP: {TP[argmax]} .. FP: {FP[argmax]} .. TN: {TN[argmax]} .. FN: {FN[argmax]}')\n",
    "    print(f'..... {FDR[argmax]}% of correctly classified images are below the threshold (FDR)')\n",
    "    print(f'while {NPV[argmax]}% of incorrectly classified images are below the threshold (NPV)')    \n",
    "    print(f'precision: {round(TP[argmax]/(TP[argmax]+FP[argmax]), 2)}')\n",
    "    print(f'recall: {round(TP[argmax]/(TP[argmax]+FN[argmax]), 2)}')\n",
    "\n",
    "    plt.plot(x, fail_rate)\n",
    "    plt.plot(x, work_load)\n",
    "    th_best = np.zeros(len(x))\n",
    "    th_best.fill(x[argmax])\n",
    "    th_best = list(th_best)\n",
    "    plt.plot(th_best, FDR)\n",
    "#     plt.plot(x, fail_rate)\n",
    "#     plt.plot(x, work_load)\n",
    "    \n",
    "    #plt.legend(['FDR', 'NPV', 'th_best', 'fail_rate', 'work_load'])\n",
    "    plt.legend(['fail_rate', 'work_load', 'th_best'])\n",
    "#     plt.xlabel('Threshold')\n",
    "#     plt.ylabel('% of Images')\n",
    "    plt.set_xlabel('Threshold')\n",
    "    plt.set_ylabel('% of Images')\n",
    "    #plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "#     plt.title(title)\n",
    "    plt.set_title(title)\n",
    "\n",
    "    # plt.annotate('best threshold', \n",
    "    #              xy=(lst_threshold[argmax], lst_unmatch[argmax]), \n",
    "    #              #xytext=(lst_threshold[argmax]-20, lst_unmatch[argmax]-0.2), \n",
    "    #              xytext=(20, 0.2), \n",
    "    #              arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "    #              )\n",
    "\n",
    "    plt.text(x[argmax]-0.2*x[argmax], .6, f'best threshold={round(x[argmax],2)}')\n",
    "    #plt.text(0.07, .92, f'best threshold={round(lst_threshold[argmax],2)}')\n",
    "    #plt.set_figure(figsize=(18, 18))\n",
    "    #plt.savefig(f'../graphs/best_score_{percent_of_images*100}_{round(y_match[i],4)*100}.png')\n",
    "#     plt.show()\n",
    "\n",
    "    print(df_threshold.to_string(index=False))        \n",
    "    \n",
    "    return df_Res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_results_eval[(df_results_eval['actual_class'] == df_results_eval['best_pred']) &\n",
    "                                         (df_results_eval['best_score'] >= .96)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Score - Softmax & Certainty (Top-2)\n",
    "#### (Horizontal - Between classes [after averaging the results for the ensembles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "fig, ((plt_sub1, plt_sub2)) = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n",
    "# fig, ((plt_sub1)) = plt.subplots(nrows=1, ncols=1, figsize=(15,4))\n",
    "\n",
    "df_Softmax = plot_metrics_test(plt_sub1, title='Softmax Score', metric_name='best_score', step_size=0.01, is_norm=False)\n",
    "df_Top2 = plot_metrics_test(plt_sub2, title='Top-2 Difference', metric_name='Certainty', step_size=1, is_norm=False)\n",
    "\n",
    "plt.show()\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(df_Softmax.index), list(df_Softmax['fail_rate']))\n",
    "plt.plot(list(df_Softmax.index), list(df_Softmax['work_load']))\n",
    "# th_best = np.zeros(len(x))\n",
    "# th_best.fill(x[argmax])\n",
    "# th_best = list(th_best)\n",
    "# plt.plot(th_best, FDR)\n",
    "\n",
    "plt.legend(['fail_rate', 'work_load'])\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('% of Images')\n",
    "# plt.set_xlabel('Threshold')\n",
    "# plt.set_ylabel('% of Images')\n",
    "#plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "#     plt.title(title)\n",
    "# plt.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(2, 1, 1)\n",
    "ax2 = fig.add_subplot(2, 1, 2)\n",
    "\n",
    "line1, = ax1.plot(list(df_Softmax['fail_rate']), color='blue', lw=2)\n",
    "line2, = ax2.plot(list(df_Softmax['work_load']), color='blue', lw=2)\n",
    "\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(3.913709-3.622185)\n",
    "print((3.913709-3.622185)/3.622185*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3.913709-3.622185)/3.622185*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you accept to have 1% error rate, then you need to check 2.62% of the images (360) manually\n",
    "# (if I start searching the val from 0, work_load=2.59% ... if start the val from min_val, 2,62%)\n",
    "# threshold you will use is = 0.3287 for Softmax. You'll accept anything above this value as correctly classified\n",
    "df_Softmax[df_Softmax['fail_rate']<0.5] \n",
    "# (%) e.g. Fail Rate = FP/n_all_images\n",
    "# if 0.1 then you were guaranteed to have 99.9% success if you manually verify 773 images (5.63%) out of 13721 images\n",
    "# if   1 then you were guaranteed to have 99.0% success if you manually verify 356 images (2.59%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Softmax[df_Softmax['val']>=0.5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_flexible = df_Softmax[(df_Softmax['fail_rate']>=0.5) & (df_Softmax['fail_rate']<=1)] \n",
    "df_flexible = df_Softmax[(df_Softmax['work_load']<=5) & (df_Softmax['fail_rate']<=1)] \n",
    "lst_flexible = list(df_flexible['val'])\n",
    "lst_flexible_workload = list(df_flexible['work_load'])\n",
    "print(f'{len(lst_flexible)} values from {min(lst_flexible)} to {max(lst_flexible)} having fail rate between 0.5 and 1.0')\n",
    "print(f'workload from {min(lst_flexible_workload)} to {max(lst_flexible_workload)}')\n",
    "print(3.913709-3.622185)\n",
    "print((3.913709-3.622185)/3.622185*100)\n",
    "\n",
    "df_flexible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "df_Softmax['effectiveness'] = (df_Softmax['fail_rate']*.66) + (df_Softmax['work_load']*.33)\n",
    "df_Softmax['effectiveness2'] = (df_Softmax['fail_rate']*.75) + (df_Softmax['work_load']*.25)\n",
    "df_Softmax['effectiveness3'] = (df_Softmax['fail_rate']*.7) + (df_Softmax['work_load']*.3)\n",
    "df_Softmax\n",
    "#df_Softmax[(df_Softmax['effectiveness']>1.55) & (df_Softmax['effectiveness']<1.65)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Top2[df_Top2['fail_rate']<0.5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flexible = df_Top2[(df_Top2['work_load']<=5) & (df_Top2['fail_rate']<=1)] \n",
    "lst_flexible = list(df_flexible['val'])\n",
    "lst_flexible_workload = list(df_flexible['work_load'])\n",
    "print(f'{len(lst_flexible)} values from {min(lst_flexible)} to {max(lst_flexible)} having fail rate between 0.5 and 1.0')\n",
    "print(f'workload from {min(lst_flexible_workload)} to {max(lst_flexible_workload)}')\n",
    "\n",
    "print(3.913709-3.622185)\n",
    "print((3.913709-3.622185)/3.622185*100)\n",
    "\n",
    "df_flexible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_results_eval[df_results_eval['best_score']<=0.3287])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_results_eval[(df_results_eval['best_score']<=0.387) & df_results_eval['Incorrect']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_results_eval[df_results_eval['best_score']<=0.3487])/len(df_results_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_results_eval)*0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_1 = [1,2,3,4]\n",
    "lst_2 = ['a', 'b', 'c', 'd']\n",
    "dict_x = {'lst_1': lst_1, 'lst_2': lst_2}\n",
    "dict_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy of Ensemble-Softmax [sum of entr(means)] & VAR\n",
    "#### (Horizontal - Between classes [after averaging the results for the ensembles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((plt_sub1, plt_sub2)) = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n",
    "'''\n",
    "here, we calculate the entropy of the mean of the predictions e.g.:\n",
    "sm_e.i = Softmax value of the 'e'th ensemble of 'i'th class\n",
    "ensemble_model1 = [sm_1.1, sm_1.2, ..., sm_1.24]\n",
    "ensemble_model2 = [sm_2.1, sm_2.2, ..., sm_2.24]\n",
    "sm1 = (sm_1.1 + sm_2.1)/2\n",
    "ensemble_model_mean = [sm1, sm2, ..., sm24]\n",
    "entropy will be calculated for ensemble_model_mean and sum of those individual means\n",
    "HIGH entropy indicates HIGH information, which means HIGH UNCERTAINTY. so, we take the reverse of it \n",
    "to measure the certainty. THEN HIGH CERTAINTY is expected for CORRECTLY classified images.\n",
    "LOW entropy indicates LOW information, which means LOW UNCERTAINTY=HIGH CERTAINTY.\n",
    "NOTE: This entropy values normalized according to the highest possible entropy, so the max they can take is 1.0.\n",
    "But since it is almost impossible have E_max, we see the max<1\n",
    "'''\n",
    "\n",
    "df_Entropy_H = plot_metrics_test(plt_sub1, title='Entropy of Ensemble-Softmax [sum of entr(means)]', metric_name='u_entr',\n",
    "             step_size=0.0096, higher_better=False, is_norm=False)\n",
    "\n",
    "'''\n",
    "var will be calculated for ensemble_model_mean\n",
    "HIGH variance indicates that the values are spreaded out from each other.\n",
    "LOW variance indicates that the data points tend to be very close to the mean.\n",
    "HIGH variance indicates that the data points are very spread out from the mean, and from one another.\n",
    "so, we expect HIGHer variance value if there is a class which is much higher than others.\n",
    "'''\n",
    "df_Var_H = plot_metrics_test(plt_sub2, title='var', metric_name='var', step_size=0.0004, higher_better=True, is_norm=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "df_Entropy_H[df_Entropy_H['fail_rate']>=0.45]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flexible = df_Entropy_H[(df_Entropy_H['work_load']<=5) & (df_Entropy_H['fail_rate']<=1)] \n",
    "lst_flexible = list(df_flexible['val'])\n",
    "lst_flexible_workload = list(df_flexible['work_load'])\n",
    "print(f'{len(lst_flexible)} values from {min(lst_flexible)} to {max(lst_flexible)} having fail rate between 0.5 and 1.0')\n",
    "print(f'workload from {min(lst_flexible_workload)} to {max(lst_flexible_workload)}')\n",
    "\n",
    "print(3.731506-3.622185)\n",
    "print((3.731506-3.622185)/3.622185*100)\n",
    "\n",
    "df_flexible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Var_H[df_Var_H['fail_rate']<0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flexible = df_Var_H[(df_Var_H['work_load']<=5) & (df_Var_H['fail_rate']<=1)] \n",
    "lst_flexible = list(df_flexible['val'])\n",
    "lst_flexible_workload = list(df_flexible['work_load'])\n",
    "print(f'{len(lst_flexible)} values from {min(lst_flexible)} to {max(lst_flexible)} having fail rate between 0.5 and 1.0')\n",
    "print(f'workload from {min(lst_flexible_workload)} to {max(lst_flexible_workload)}')\n",
    "\n",
    "print(3.753371-3.622185)\n",
    "print((3.753371-3.622185)/3.622185*100)\n",
    "\n",
    "df_flexible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bhattacharyya Coefficient & JSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((plt_sub1, plt_sub2)) = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n",
    "\"\"\"\n",
    "Bhattacharyya Coefficient (BC):\n",
    "The Bhattacharyya coefficient is a measure of the amount of overlap between \n",
    "two statistical samples or populations.\n",
    "\"\"\"\n",
    "df_results_eval['BC']=df_results_eval['best_score']*df_results_eval['best_2nd_score']\n",
    "df_BC=plot_metrics_test(plt_sub1, title='Bhattacharyya Coefficient', metric_name='BC', step_size=0.01, is_norm=False)\n",
    "df_JSD=plot_metrics_test(plt_sub2, title='JSD', metric_name='P_jsd', step_size=0.01, higher_better=True, is_norm=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_JSD[df_JSD['fail_rate']>0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BC[df_BC['fail_rate']>0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## var_Top1 (Vertical - Between ensembles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((plt_sub1)) = plt.subplots(nrows=1, ncols=1, figsize=(9,6))\n",
    "lst_var = []\n",
    "'''\n",
    "here, we calculate the variance of the best predictions among the ensemble members. e.g.:\n",
    "sm_e.i = Softmax value of the 'e'th ensemble of 'i'th class\n",
    "ensemble_model1 = [sm_1.1, sm_1.2, ..., sm_1.24]\n",
    "ensemble_model2 = [sm_2.1, sm_2.2, ..., sm_2.24]\n",
    "if the highest mean belongs to class_2, then\n",
    "var will be calculated for sm_1.2 and sm_2.2\n",
    "The variance in this case shows how much the models agree on a decision unlike the variance calculated\n",
    "for the entire class results of mean-ensemble values.\n",
    "'''\n",
    "\n",
    "for x in df_results_eval.index:\n",
    "    best_index = df_results_eval.loc[x, 'best_index']\n",
    "    lst_var.append(np.var(tuc1.df_result_ensemble.loc[x, 'outputs_all'][:, best_index]))\n",
    "\n",
    "df_results_eval['var_Top1'] = lst_var\n",
    "# plot_metrics(title='var_Top1', metric_name='var_Top1', min_max_step=(0.9, 0.99, 0.01), is_norm=False)\n",
    "df_var_Top1=plot_metrics_test(plt_sub1, title='var_Top1', metric_name='var_Top1', step_size=0.001, higher_better=True, is_norm=False)\n",
    "df_Var_H = plot_metrics_test(plt_sub2, title='var', metric_name='var', step_size=0.0005, higher_better=True, is_norm=False)\n",
    "\n",
    "#plot_metrics_p(plt_sub3, title='Softmax Score', metric_name='best_score', step_size=0.01, is_norm=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuc1.df_result_ensemble.loc[1, 'outputs_all']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy (same as above (horizontal-entropy) but this time not normalized according to the max value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((plt_sub1)) = plt.subplots(nrows=1, ncols=1, figsize=(9,6))\n",
    "plot_metrics(plt_sub1, title='Entr', metric_name='entr', step_size=0.01, higher_better=False, is_norm=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STD (Horizontal - Between classes [after averaging the results for the ensembles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_metrics(title='std', metric_name='std', min_max_step=(0.9, 0.99, 0.01), is_norm=False)\n",
    "fig, ((plt_sub1)) = plt.subplots(nrows=1, ncols=1, figsize=(9,6))\n",
    "plot_metrics(plt_sub1, title='std', metric_name='std', step_size=0.001, higher_better=True, is_norm=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuc1.df_result_ensemble[:1]\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "c_list = ['picture','uncertainty', 'actual_class', 'best_pred','best_score', 'best_2nd_score', 'P_jsd', 'P_info', 'std', 'u_entr', 'var_Top1']\n",
    "df_results_eval[df_results_eval['actual_class'] != df_results_eval['best_pred']][c_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_eval[df_results_eval['actual_class'] == df_results_eval['best_pred']][c_list][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuc1.df_result_ensemble[tuc1.df_result_ensemble['picture'] == 'MA160814197500041.070-K_4_0_.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# xx=np.array([1,2,3,4,0])\n",
    "xx=np.array([1/5,1/5,1/5,1/5,1/5])\n",
    "Counter(xx)\n",
    "# print(np.bincount(xx))\n",
    "# np.var(np.bincount(xx))\n",
    "# entr(np.bincount(xx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuc1.df_result_ensemble[tuc1.df_result_ensemble['picture'] == 'MA160873676300027.057-K_20_1_.png']['outputs_all'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_eval.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuc1.show_results(result = 'ALL') # mean=mean top-2 uncertainty of the given class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx=np.array([1,2,8,4,5])\n",
    "np.argmax(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuc1.show_results(result = 'match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuc1.show_results(result = 'unmatch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuc1.show_results(result = 'combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "tuc1.show_results(result = 'ALL2nd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_eval[df_results_eval['actual_class'] != \n",
    "                df_results_eval['best_pred']].loc[:,['picture','actual_class', 'best_pred', 'Certainty']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_eval.loc[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuc1.df_uncertainty.loc[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_eval[df_results_eval['actual_class'] == \n",
    "                df_results_eval['best_pred']].loc[:,['picture','actual_class', 'best_pred', 'Certainty']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "plt.figure()\n",
    "class_names = range(24)\n",
    "plot_confusion_matrix(confusion, classes=class_names, normalize=False,title='Normalized confusion matrix')\n",
    "# plot_confusion_matrix(confusion, normalize=True,title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/35572000/how-can-i-plot-a-confusion-matrix\n",
    "l_label = list(df_results_eval['actual_class'])\n",
    "l_pred = list(df_results_eval['best_pred'])\n",
    "performance.plot_confusion_matrix(l_label, l_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(l_label, l_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/multi-class-classification-extracting-performance-metrics-from-the-confusion-matrix-b379b427a872\n",
    "#https://towardsdatascience.com/confusion-matrix-for-your-multi-class-machine-learning-model-ff9aa3bf7826#:~:text=False%20Positive%20(FP)%3A%20It,the%20positive%20class%20as%20negative.\n",
    "FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix) \n",
    "FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "TP = np.diag(cnf_matrix)\n",
    "TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "# Overall accuracy for each class\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sum_TP)/(sum_TP+sum_FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_TP = sum(TP)\n",
    "sum_TN = sum(TN)\n",
    "sum_FN = sum(FN)\n",
    "sum_FP = sum(FP)\n",
    "sum_FN/(sum_TP+sum_FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sum_TP+sum_TN)/(sum_TP+sum_FP+sum_FN+sum_TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(FNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_FN/(sum_TP+sum_FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_label_idx = list(df_results_eval['class_idx'])\n",
    "l_pred_idx = list(df_results_eval['best_index'])\n",
    "l_predict_proba = list(df_results_eval['Mean'])\n",
    "roc_auc_score(l_label_idx, l_predict_proba, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "arr_label_idx = np.array(l_label_idx).reshape(-1,1)\n",
    "arr_predict_proba = np.array(l_predict_proba)\n",
    "\n",
    "#label_encoder = LabelEncoder()\n",
    "#l_label_int = label_encoder.fit_transform(l_label_int)    \n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "onehot_encoded = onehot_encoder.fit_transform(arr_label_idx)   # onehot_encoded => array(852,24)=(n_samples, n_classes)\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"ALL\"], tpr[\"ALL\"], _ = roc_curve(onehot_encoded.ravel(), arr_predict_proba.ravel())\n",
    "roc_auc[\"ALL\"] = auc(fpr[\"ALL\"], tpr[\"ALL\"])\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[\"ALL\"], tpr[\"ALL\"], color='darkorange',\n",
    "lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[\"ALL\"])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "fpr_ALL, tpr_ALL, roc_auc_val = fpr['ALL'], tpr['ALL'], roc_auc[\"ALL\"]\n",
    "# print(f\"fpr_ALL: {fpr_ALL} .. ttpr_ALL: {tpr_ALL} .. roc_auc_val: {roc_auc_val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(arr_label_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(metrics.confusion_matrix(l_label, l_pred))\n",
    "print(metrics.classification_report(l_label, l_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_label_idx = np.array(l_label_idx).reshape(-1,1)\n",
    "arr_predict_proba = np.array(l_predict_proba)\n",
    "\n",
    "# plt_class = for which class you want to plot the ROC CURVE\n",
    "fpr_micro, tpr_micro, roc_auc_val = \\\n",
    "performance.plot_roc_curve(arr_label_idx, arr_predict_proba, n_classes=24, plt_class=22)\n",
    "\n",
    "print(round(roc_auc_val,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_eval.iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df_results_eval[df_results_eval['picture']=='MA160814197500042.017-K_9_0_.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_eval.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results_eval\n",
    "# output = tuc1.softmax_and_reshape(tuc1.df_result_ensemble.loc[0,'outputs_all'])\n",
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.special import entr\n",
    "# entr(output[:,8]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# entr_per_model=entr(output).sum(axis=1)/np.log(2)\n",
    "# entr_per_model2=entr(output).sum(axis=0)/np.log(2)\n",
    "# print(entr_per_model)\n",
    "# print(np.mean(entr_per_model))\n",
    "# print(entr_per_model2)\n",
    "# print(np.mean(entr_per_model2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=0\n",
    "# # variance of the scores of the best prediction (pred with the highest score)\n",
    "# # indexes are preserved between 2 dataframes\n",
    "# np.var(tuc1.normalize_array_preprocess(tuc1.df_result_ensemble.loc[x,\n",
    "#                                         'outputs_all'])[:,df_results_eval.loc[x,'best_index']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_results_eval)):\n",
    "    if i %1000 == 0:\n",
    "        pic1 = df_results_eval.loc[i,'picture']\n",
    "        pic2 = tuc1.df_result_ensemble.loc[i,'picture']\n",
    "        print(f'df_results_eval: {pic1} ... df_result_ensemble: {pic2}')\n",
    "    if df_results_eval.loc[i,'picture'] != tuc1.df_result_ensemble.loc[i,'picture']:\n",
    "        print('mismatch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuc1.df_result_ensemble.iloc[0:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuc1.df_result_ensemble.loc[0,'outputs_all'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuc1.df_result_ensemble.loc[:0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuc1.df_result_ensemble['outputs_all'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=0\n",
    "t_test=tuc1.softmax_and_reshape(tuc1.df_result_ensemble.loc[x, 'outputs_all'])[:,df_results_eval.loc[x,'best_index']]\n",
    "t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(tuc1.df_result_ensemble.loc[0, 'outputs_all'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuc1.df_result_ensemble.loc[0, 'outputs_all'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuc1.df_result_ensemble.loc[0, 'outputs_all'][:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "softmax(tuc1.df_result_ensemble.loc[0, 'outputs_all'][:,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=0\n",
    "tuc1.normalize_array_preprocess(tuc1.df_result_ensemble.loc[x,'outputs_all'])[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuc1.normalize_array_preprocess(tuc1.df_result_ensemble.loc[x,'outputs_all'])[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=0\n",
    "np.argmax(tuc1.normalize_array_preprocess(tuc1.df_result_ensemble.loc[x,'outputs_all'])[1:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=0\n",
    "np.argmax(tuc1.df_result_ensemble.loc[:,'outputs_all'][x][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuc1.df_result_ensemble.loc[:10,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
